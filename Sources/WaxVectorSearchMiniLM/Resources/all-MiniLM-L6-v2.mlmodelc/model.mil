program(1.3)
[buildInfo = dict<string, string>({{"coremlc-component-MIL", "3500.14.1"}, {"coremlc-version", "3500.32.1"}, {"coremltools-component-torch", "2.7.1"}, {"coremltools-source-dialect", "TorchScript"}, {"coremltools-version", "9.0"}})]
{
    func main<ios18>(tensor<int32, [?, ?]> attention_mask, tensor<int32, [?, ?]> input_ids) [FlexibleShapeInformation = tuple<tuple<string, dict<string, tensor<int32, [?]>>>, tuple<string, dict<string, dict<string, tensor<int32, [?]>>>>>((("DefaultShapes", {{"attention_mask", [1, 32]}, {"input_ids", [1, 32]}}), ("EnumeratedShapes", {{"000187c4", {{"attention_mask", [64, 64]}, {"input_ids", [64, 64]}}}, {"090f2853", {{"attention_mask", [1, 128]}, {"input_ids", [1, 128]}}}, {"0a731900", {{"attention_mask", [1, 256]}, {"input_ids", [1, 256]}}}, {"14e22cc3", {{"attention_mask", [8, 64]}, {"input_ids", [8, 64]}}}, {"155d1fbb", {{"attention_mask", [64, 384]}, {"input_ids", [64, 384]}}}, {"1a2a12fc", {{"attention_mask", [16, 512]}, {"input_ids", [16, 512]}}}, {"22c267bf", {{"attention_mask", [64, 128]}, {"input_ids", [64, 128]}}}, {"24cf7ddf", {{"attention_mask", [64, 32]}, {"input_ids", [64, 32]}}}, {"2721a294", {{"attention_mask", [16, 32]}, {"input_ids", [16, 32]}}}, {"29d5bec5", {{"attention_mask", [32, 256]}, {"input_ids", [32, 256]}}}, {"3a8c1bc2", {{"attention_mask", [32, 512]}, {"input_ids", [32, 512]}}}, {"4b9590f0", {{"attention_mask", [16, 256]}, {"input_ids", [16, 256]}}}, {"50450b3e", {{"attention_mask", [16, 128]}, {"input_ids", [16, 128]}}}, {"517b156a", {{"attention_mask", [8, 512]}, {"input_ids", [8, 512]}}}, {"53dd2036", {{"attention_mask", [32, 384]}, {"input_ids", [32, 384]}}}, {"6526d012", {{"attention_mask", [8, 32]}, {"input_ids", [8, 32]}}}, {"7b263bfe", {{"attention_mask", [1, 512]}, {"input_ids", [1, 512]}}}, {"89020357", {{"attention_mask", [32, 128]}, {"input_ids", [32, 128]}}}, {"92e182a7", {{"attention_mask", [1, 384]}, {"input_ids", [1, 384]}}}, {"964b98d6", {{"attention_mask", [64, 512]}, {"input_ids", [64, 512]}}}, {"a28995a1", {{"attention_mask", [16, 64]}, {"input_ids", [16, 64]}}}, {"a4e8f51c", {{"attention_mask", [32, 32]}, {"input_ids", [32, 32]}}}, {"aa3a1438", {{"attention_mask", [8, 128]}, {"input_ids", [8, 128]}}}, {"b0234bc7", {{"attention_mask", [8, 384]}, {"input_ids", [8, 384]}}}, {"ba32981e", {{"attention_mask", [16, 384]}, {"input_ids", [16, 384]}}}, {"cc37bcd3", {{"attention_mask", [8, 256]}, {"input_ids", [8, 256]}}}, {"d2679837", {{"attention_mask", [64, 256]}, {"input_ids", [64, 256]}}}, {"d8f542e5", {{"attention_mask", [1, 64]}, {"input_ids", [1, 64]}}}, {"e78bf925", {{"attention_mask", [32, 64]}, {"input_ids", [32, 64]}}}, {"f5a604ed", {{"attention_mask", [1, 32]}, {"input_ids", [1, 32]}}}})))] {
            tensor<int32, [1, 512]> model_embeddings_position_ids = const()[name = string("model_embeddings_position_ids"), val = tensor<int32, [1, 512]>(BLOBFILE(path = string("@model_path/weights/weight.bin"), offset = uint64(64)))];
            tensor<int32, [?, ?]> input_1 = sub(x = input_ids, y = input_ids)[name = string("sub_0")];
            int32 var_22 = const()[name = string("op_22"), val = int32(32)];
            int32 var_23 = const()[name = string("op_23"), val = int32(12)];
            int32 var_24 = const()[name = string("op_24"), val = int32(-1)];
            int32 var_27 = const()[name = string("op_27"), val = int32(384)];
            tensor<int32, [1]> var_42_axes_0 = const()[name = string("op_42_axes_0"), val = tensor<int32, [1]>([1])];
            tensor<int32, [?, 1, ?]> var_42 = expand_dims(axes = var_42_axes_0, x = attention_mask)[name = string("op_42")];
            tensor<int32, [1]> var_43_axes_0 = const()[name = string("op_43_axes_0"), val = tensor<int32, [1]>([2])];
            tensor<int32, [?, 1, 1, ?]> var_43 = expand_dims(axes = var_43_axes_0, x = var_42)[name = string("op_43")];
            fp16 var_29_to_fp16 = const()[name = string("op_29_to_fp16"), val = fp16(0x1p+0)];
            string var_45_to_fp16_dtype_0 = const()[name = string("op_45_to_fp16_dtype_0"), val = string("fp16")];
            tensor<fp16, [?, 1, 1, ?]> var_43_to_fp16 = cast(dtype = var_45_to_fp16_dtype_0, x = var_43)[name = string("cast_117")];
            tensor<fp16, [?, 1, 1, ?]> var_46_cast_fp16 = sub(x = var_29_to_fp16, y = var_43_to_fp16)[name = string("op_46_cast_fp16")];
            fp16 var_47_to_fp16 = const()[name = string("op_47_to_fp16"), val = fp16(-inf)];
            tensor<fp16, [?, 1, 1, ?]> attention_mask_cast_fp16 = mul(x = var_46_cast_fp16, y = var_47_to_fp16)[name = string("attention_mask_cast_fp16")];
            tensor<int32, [2]> var_54_shape = shape(x = input_ids)[name = string("op_54_shape")];
            int32 gather_0_axis_0 = const()[name = string("gather_0_axis_0"), val = int32(0)];
            int32 gather_0_batch_dims_0 = const()[name = string("gather_0_batch_dims_0"), val = int32(0)];
            bool gather_0_validate_indices_0 = const()[name = string("gather_0_validate_indices_0"), val = bool(false)];
            string var_54_shape_to_int16_dtype_0 = const()[name = string("op_54_shape_to_int16_dtype_0"), val = string("int16")];
            uint16 gather_0_indices_0_to_uint16 = const()[name = string("gather_0_indices_0_to_uint16"), val = uint16(1)];
            tensor<int16, [2]> var_54_shape_to_int16 = cast(dtype = var_54_shape_to_int16_dtype_0, x = var_54_shape)[name = string("cast_116")];
            int16 gather_0_cast_uint16 = gather(axis = gather_0_axis_0, batch_dims = gather_0_batch_dims_0, indices = gather_0_indices_0_to_uint16, validate_indices = gather_0_validate_indices_0, x = var_54_shape_to_int16)[name = string("gather_0_cast_uint16")];
            string gather_0_cast_uint16_to_int32_dtype_0 = const()[name = string("gather_0_cast_uint16_to_int32_dtype_0"), val = string("int32")];
            int32 concat_0_values0_0 = const()[name = string("concat_0_values0_0"), val = int32(1)];
            int32 concat_0_axis_0 = const()[name = string("concat_0_axis_0"), val = int32(0)];
            bool concat_0_interleave_0 = const()[name = string("concat_0_interleave_0"), val = bool(false)];
            int32 gather_0_cast_uint16_to_int32 = cast(dtype = gather_0_cast_uint16_to_int32_dtype_0, x = gather_0_cast_uint16)[name = string("cast_115")];
            tensor<int32, [2]> concat_0 = concat(axis = concat_0_axis_0, interleave = concat_0_interleave_0, values = (concat_0_values0_0, gather_0_cast_uint16_to_int32))[name = string("concat_0")];
            tensor<int32, [2]> input_3_begin_0 = const()[name = string("input_3_begin_0"), val = tensor<int32, [2]>([0, 0])];
            tensor<bool, [2]> input_3_end_mask_0 = const()[name = string("input_3_end_mask_0"), val = tensor<bool, [2]>([true, false])];
            tensor<int32, [1, ?]> input_3 = slice_by_index(begin = input_3_begin_0, end = concat_0, end_mask = input_3_end_mask_0, x = model_embeddings_position_ids)[name = string("input_3")];
            int32 inputs_embeds_axis_0 = const()[name = string("inputs_embeds_axis_0"), val = int32(0)];
            int32 inputs_embeds_batch_dims_0 = const()[name = string("inputs_embeds_batch_dims_0"), val = int32(0)];
            bool inputs_embeds_validate_indices_0 = const()[name = string("inputs_embeds_validate_indices_0"), val = bool(false)];
            tensor<fp16, [30522, 384]> model_embeddings_word_embeddings_weight_to_fp16 = const()[name = string("model_embeddings_word_embeddings_weight_to_fp16"), val = tensor<fp16, [30522, 384]>(BLOBFILE(path = string("@model_path/weights/weight.bin"), offset = uint64(2176)))];
            string input_ids_to_uint16_dtype_0 = const()[name = string("input_ids_to_uint16_dtype_0"), val = string("uint16")];
            tensor<uint16, [?, ?]> input_ids_to_uint16 = cast(dtype = input_ids_to_uint16_dtype_0, x = input_ids)[name = string("cast_114")];
            tensor<fp16, [?, ?, 384]> inputs_embeds_cast_fp16_cast_uint16 = gather(axis = inputs_embeds_axis_0, batch_dims = inputs_embeds_batch_dims_0, indices = input_ids_to_uint16, validate_indices = inputs_embeds_validate_indices_0, x = model_embeddings_word_embeddings_weight_to_fp16)[name = string("inputs_embeds_cast_fp16_cast_uint16")];
            int32 token_type_embeddings_1_axis_0 = const()[name = string("token_type_embeddings_1_axis_0"), val = int32(0)];
            int32 token_type_embeddings_1_batch_dims_0 = const()[name = string("token_type_embeddings_1_batch_dims_0"), val = int32(0)];
            bool token_type_embeddings_1_validate_indices_0 = const()[name = string("token_type_embeddings_1_validate_indices_0"), val = bool(false)];
            tensor<fp16, [2, 384]> model_embeddings_token_type_embeddings_weight_to_fp16 = const()[name = string("model_embeddings_token_type_embeddings_weight_to_fp16"), val = tensor<fp16, [2, 384]>(BLOBFILE(path = string("@model_path/weights/weight.bin"), offset = uint64(23443136)))];
            string input_1_to_uint16_dtype_0 = const()[name = string("input_1_to_uint16_dtype_0"), val = string("uint16")];
            tensor<uint16, [?, ?]> input_1_to_uint16 = cast(dtype = input_1_to_uint16_dtype_0, x = input_1)[name = string("cast_113")];
            tensor<fp16, [?, ?, 384]> token_type_embeddings_1_cast_fp16_cast_uint16 = gather(axis = token_type_embeddings_1_axis_0, batch_dims = token_type_embeddings_1_batch_dims_0, indices = input_1_to_uint16, validate_indices = token_type_embeddings_1_validate_indices_0, x = model_embeddings_token_type_embeddings_weight_to_fp16)[name = string("token_type_embeddings_1_cast_fp16_cast_uint16")];
            tensor<fp16, [?, ?, 384]> embeddings_1_cast_fp16 = add(x = inputs_embeds_cast_fp16_cast_uint16, y = token_type_embeddings_1_cast_fp16_cast_uint16)[name = string("embeddings_1_cast_fp16")];
            int32 position_embeddings_1_axis_0 = const()[name = string("position_embeddings_1_axis_0"), val = int32(0)];
            int32 position_embeddings_1_batch_dims_0 = const()[name = string("position_embeddings_1_batch_dims_0"), val = int32(0)];
            bool position_embeddings_1_validate_indices_0 = const()[name = string("position_embeddings_1_validate_indices_0"), val = bool(false)];
            tensor<fp16, [512, 384]> model_embeddings_position_embeddings_weight_to_fp16 = const()[name = string("model_embeddings_position_embeddings_weight_to_fp16"), val = tensor<fp16, [512, 384]>(BLOBFILE(path = string("@model_path/weights/weight.bin"), offset = uint64(23444736)))];
            string input_3_to_uint16_dtype_0 = const()[name = string("input_3_to_uint16_dtype_0"), val = string("uint16")];
            tensor<uint16, [1, ?]> input_3_to_uint16 = cast(dtype = input_3_to_uint16_dtype_0, x = input_3)[name = string("cast_112")];
            tensor<fp16, [1, ?, 384]> position_embeddings_1_cast_fp16_cast_uint16 = gather(axis = position_embeddings_1_axis_0, batch_dims = position_embeddings_1_batch_dims_0, indices = input_3_to_uint16, validate_indices = position_embeddings_1_validate_indices_0, x = model_embeddings_position_embeddings_weight_to_fp16)[name = string("position_embeddings_1_cast_fp16_cast_uint16")];
            tensor<fp16, [?, ?, 384]> input_5_cast_fp16 = add(x = embeddings_1_cast_fp16, y = position_embeddings_1_cast_fp16_cast_uint16)[name = string("input_5_cast_fp16")];
            tensor<int32, [1]> input_7_axes_0 = const()[name = string("input_7_axes_0"), val = tensor<int32, [1]>([-1])];
            tensor<fp16, [384]> model_embeddings_LayerNorm_weight_to_fp16 = const()[name = string("model_embeddings_LayerNorm_weight_to_fp16"), val = tensor<fp16, [384]>(BLOBFILE(path = string("@model_path/weights/weight.bin"), offset = uint64(23838016)))];
            tensor<fp16, [384]> model_embeddings_LayerNorm_bias_to_fp16 = const()[name = string("model_embeddings_LayerNorm_bias_to_fp16"), val = tensor<fp16, [384]>(BLOBFILE(path = string("@model_path/weights/weight.bin"), offset = uint64(23838848)))];
            fp16 var_26_to_fp16 = const()[name = string("op_26_to_fp16"), val = fp16(0x1p-24)];
            tensor<fp16, [?, ?, 384]> input_7_cast_fp16 = layer_norm(axes = input_7_axes_0, beta = model_embeddings_LayerNorm_bias_to_fp16, epsilon = var_26_to_fp16, gamma = model_embeddings_LayerNorm_weight_to_fp16, x = input_5_cast_fp16)[name = string("input_7_cast_fp16")];
            tensor<fp16, [384, 384]> model_encoder_layer_0_attention_self_query_weight_to_fp16 = const()[name = string("model_encoder_layer_0_attention_self_query_weight_to_fp16"), val = tensor<fp16, [384, 384]>(BLOBFILE(path = string("@model_path/weights/weight.bin"), offset = uint64(23839680)))];
            tensor<fp16, [384]> model_encoder_layer_0_attention_self_query_bias_to_fp16 = const()[name = string("model_encoder_layer_0_attention_self_query_bias_to_fp16"), val = tensor<fp16, [384]>(BLOBFILE(path = string("@model_path/weights/weight.bin"), offset = uint64(24134656)))];
            tensor<fp16, [?, ?, 384]> linear_0_cast_fp16 = linear(bias = model_encoder_layer_0_attention_self_query_bias_to_fp16, weight = model_encoder_layer_0_attention_self_query_weight_to_fp16, x = input_7_cast_fp16)[name = string("linear_0_cast_fp16")];
            tensor<fp16, [384, 384]> model_encoder_layer_0_attention_self_key_weight_to_fp16 = const()[name = string("model_encoder_layer_0_attention_self_key_weight_to_fp16"), val = tensor<fp16, [384, 384]>(BLOBFILE(path = string("@model_path/weights/weight.bin"), offset = uint64(24135488)))];
            tensor<fp16, [384]> model_encoder_layer_0_attention_self_key_bias_to_fp16 = const()[name = string("model_encoder_layer_0_attention_self_key_bias_to_fp16"), val = tensor<fp16, [384]>(BLOBFILE(path = string("@model_path/weights/weight.bin"), offset = uint64(24430464)))];
            tensor<fp16, [?, ?, 384]> linear_1_cast_fp16 = linear(bias = model_encoder_layer_0_attention_self_key_bias_to_fp16, weight = model_encoder_layer_0_attention_self_key_weight_to_fp16, x = input_7_cast_fp16)[name = string("linear_1_cast_fp16")];
            tensor<int32, [3]> var_100_shape_cast_fp16 = shape(x = linear_1_cast_fp16)[name = string("op_100_shape_cast_fp16")];
            int32 gather_1_axis_0 = const()[name = string("gather_1_axis_0"), val = int32(0)];
            int32 gather_1_batch_dims_0 = const()[name = string("gather_1_batch_dims_0"), val = int32(0)];
            bool gather_1_validate_indices_0 = const()[name = string("gather_1_validate_indices_0"), val = bool(false)];
            string var_100_shape_cast_fp16_to_uint16_dtype_0 = const()[name = string("op_100_shape_cast_fp16_to_uint16_dtype_0"), val = string("uint16")];
            uint16 gather_1_indices_0_to_uint16 = const()[name = string("gather_1_indices_0_to_uint16"), val = uint16(0)];
            tensor<uint16, [3]> var_100_shape_cast_fp16_to_uint16 = cast(dtype = var_100_shape_cast_fp16_to_uint16_dtype_0, x = var_100_shape_cast_fp16)[name = string("cast_111")];
            uint16 gather_1_cast_uint16 = gather(axis = gather_1_axis_0, batch_dims = gather_1_batch_dims_0, indices = gather_1_indices_0_to_uint16, validate_indices = gather_1_validate_indices_0, x = var_100_shape_cast_fp16_to_uint16)[name = string("gather_1_cast_uint16")];
            string gather_1_cast_uint16_to_int32_dtype_0 = const()[name = string("gather_1_cast_uint16_to_int32_dtype_0"), val = string("int32")];
            int32 gather_2_axis_0 = const()[name = string("gather_2_axis_0"), val = int32(0)];
            int32 gather_2_batch_dims_0 = const()[name = string("gather_2_batch_dims_0"), val = int32(0)];
            bool gather_2_validate_indices_0 = const()[name = string("gather_2_validate_indices_0"), val = bool(false)];
            uint16 gather_2_indices_0_to_uint16 = const()[name = string("gather_2_indices_0_to_uint16"), val = uint16(1)];
            uint16 gather_2_cast_uint16 = gather(axis = gather_2_axis_0, batch_dims = gather_2_batch_dims_0, indices = gather_2_indices_0_to_uint16, validate_indices = gather_2_validate_indices_0, x = var_100_shape_cast_fp16_to_uint16)[name = string("gather_2_cast_uint16")];
            string gather_2_cast_uint16_to_int32_dtype_0 = const()[name = string("gather_2_cast_uint16_to_int32_dtype_0"), val = string("int32")];
            int32 concat_1_axis_0 = const()[name = string("concat_1_axis_0"), val = int32(0)];
            bool concat_1_interleave_0 = const()[name = string("concat_1_interleave_0"), val = bool(false)];
            int32 gather_2_cast_uint16_to_int32 = cast(dtype = gather_2_cast_uint16_to_int32_dtype_0, x = gather_2_cast_uint16)[name = string("cast_109")];
            int32 gather_1_cast_uint16_to_int32 = cast(dtype = gather_1_cast_uint16_to_int32_dtype_0, x = gather_1_cast_uint16)[name = string("cast_110")];
            tensor<int32, [4]> concat_1 = concat(axis = concat_1_axis_0, interleave = concat_1_interleave_0, values = (gather_1_cast_uint16_to_int32, gather_2_cast_uint16_to_int32, var_23, var_22))[name = string("concat_1")];
            tensor<fp16, [?, ?, 12, 32]> x_3_cast_fp16 = reshape(shape = concat_1, x = linear_1_cast_fp16)[name = string("x_3_cast_fp16")];
            tensor<fp16, [384, 384]> model_encoder_layer_0_attention_self_value_weight_to_fp16 = const()[name = string("model_encoder_layer_0_attention_self_value_weight_to_fp16"), val = tensor<fp16, [384, 384]>(BLOBFILE(path = string("@model_path/weights/weight.bin"), offset = uint64(24431296)))];
            tensor<fp16, [384]> model_encoder_layer_0_attention_self_value_bias_to_fp16 = const()[name = string("model_encoder_layer_0_attention_self_value_bias_to_fp16"), val = tensor<fp16, [384]>(BLOBFILE(path = string("@model_path/weights/weight.bin"), offset = uint64(24726272)))];
            tensor<fp16, [?, ?, 384]> linear_2_cast_fp16 = linear(bias = model_encoder_layer_0_attention_self_value_bias_to_fp16, weight = model_encoder_layer_0_attention_self_value_weight_to_fp16, x = input_7_cast_fp16)[name = string("linear_2_cast_fp16")];
            tensor<int32, [3]> var_109_shape_cast_fp16 = shape(x = linear_2_cast_fp16)[name = string("op_109_shape_cast_fp16")];
            int32 gather_3_axis_0 = const()[name = string("gather_3_axis_0"), val = int32(0)];
            int32 gather_3_batch_dims_0 = const()[name = string("gather_3_batch_dims_0"), val = int32(0)];
            bool gather_3_validate_indices_0 = const()[name = string("gather_3_validate_indices_0"), val = bool(false)];
            string var_109_shape_cast_fp16_to_uint16_dtype_0 = const()[name = string("op_109_shape_cast_fp16_to_uint16_dtype_0"), val = string("uint16")];
            uint16 gather_3_indices_0_to_uint16 = const()[name = string("gather_3_indices_0_to_uint16"), val = uint16(0)];
            tensor<uint16, [3]> var_109_shape_cast_fp16_to_uint16 = cast(dtype = var_109_shape_cast_fp16_to_uint16_dtype_0, x = var_109_shape_cast_fp16)[name = string("cast_108")];
            uint16 gather_3_cast_uint16 = gather(axis = gather_3_axis_0, batch_dims = gather_3_batch_dims_0, indices = gather_3_indices_0_to_uint16, validate_indices = gather_3_validate_indices_0, x = var_109_shape_cast_fp16_to_uint16)[name = string("gather_3_cast_uint16")];
            string gather_3_cast_uint16_to_int32_dtype_0 = const()[name = string("gather_3_cast_uint16_to_int32_dtype_0"), val = string("int32")];
            int32 gather_4_axis_0 = const()[name = string("gather_4_axis_0"), val = int32(0)];
            int32 gather_4_batch_dims_0 = const()[name = string("gather_4_batch_dims_0"), val = int32(0)];
            bool gather_4_validate_indices_0 = const()[name = string("gather_4_validate_indices_0"), val = bool(false)];
            uint16 gather_4_indices_0_to_uint16 = const()[name = string("gather_4_indices_0_to_uint16"), val = uint16(1)];
            uint16 gather_4_cast_uint16 = gather(axis = gather_4_axis_0, batch_dims = gather_4_batch_dims_0, indices = gather_4_indices_0_to_uint16, validate_indices = gather_4_validate_indices_0, x = var_109_shape_cast_fp16_to_uint16)[name = string("gather_4_cast_uint16")];
            string gather_4_cast_uint16_to_int32_dtype_0 = const()[name = string("gather_4_cast_uint16_to_int32_dtype_0"), val = string("int32")];
            int32 concat_2_axis_0 = const()[name = string("concat_2_axis_0"), val = int32(0)];
            bool concat_2_interleave_0 = const()[name = string("concat_2_interleave_0"), val = bool(false)];
            int32 gather_4_cast_uint16_to_int32 = cast(dtype = gather_4_cast_uint16_to_int32_dtype_0, x = gather_4_cast_uint16)[name = string("cast_106")];
            int32 gather_3_cast_uint16_to_int32 = cast(dtype = gather_3_cast_uint16_to_int32_dtype_0, x = gather_3_cast_uint16)[name = string("cast_107")];
            tensor<int32, [4]> concat_2 = concat(axis = concat_2_axis_0, interleave = concat_2_interleave_0, values = (gather_3_cast_uint16_to_int32, gather_4_cast_uint16_to_int32, var_23, var_22))[name = string("concat_2")];
            tensor<fp16, [?, ?, 12, 32]> x_7_cast_fp16 = reshape(shape = concat_2, x = linear_2_cast_fp16)[name = string("x_7_cast_fp16")];
            tensor<int32, [4]> var_113 = const()[name = string("op_113"), val = tensor<int32, [4]>([0, 2, 1, 3])];
            tensor<int32, [3]> var_115_shape_cast_fp16 = shape(x = linear_0_cast_fp16)[name = string("op_115_shape_cast_fp16")];
            int32 gather_5_axis_0 = const()[name = string("gather_5_axis_0"), val = int32(0)];
            int32 gather_5_batch_dims_0 = const()[name = string("gather_5_batch_dims_0"), val = int32(0)];
            bool gather_5_validate_indices_0 = const()[name = string("gather_5_validate_indices_0"), val = bool(false)];
            string var_115_shape_cast_fp16_to_uint16_dtype_0 = const()[name = string("op_115_shape_cast_fp16_to_uint16_dtype_0"), val = string("uint16")];
            uint16 gather_5_indices_0_to_uint16 = const()[name = string("gather_5_indices_0_to_uint16"), val = uint16(0)];
            tensor<uint16, [3]> var_115_shape_cast_fp16_to_uint16 = cast(dtype = var_115_shape_cast_fp16_to_uint16_dtype_0, x = var_115_shape_cast_fp16)[name = string("cast_105")];
            uint16 gather_5_cast_uint16 = gather(axis = gather_5_axis_0, batch_dims = gather_5_batch_dims_0, indices = gather_5_indices_0_to_uint16, validate_indices = gather_5_validate_indices_0, x = var_115_shape_cast_fp16_to_uint16)[name = string("gather_5_cast_uint16")];
            string gather_5_cast_uint16_to_int32_dtype_0 = const()[name = string("gather_5_cast_uint16_to_int32_dtype_0"), val = string("int32")];
            int32 gather_6_axis_0 = const()[name = string("gather_6_axis_0"), val = int32(0)];
            int32 gather_6_batch_dims_0 = const()[name = string("gather_6_batch_dims_0"), val = int32(0)];
            bool gather_6_validate_indices_0 = const()[name = string("gather_6_validate_indices_0"), val = bool(false)];
            uint16 gather_6_indices_0_to_uint16 = const()[name = string("gather_6_indices_0_to_uint16"), val = uint16(1)];
            uint16 gather_6_cast_uint16 = gather(axis = gather_6_axis_0, batch_dims = gather_6_batch_dims_0, indices = gather_6_indices_0_to_uint16, validate_indices = gather_6_validate_indices_0, x = var_115_shape_cast_fp16_to_uint16)[name = string("gather_6_cast_uint16")];
            string gather_6_cast_uint16_to_int32_dtype_0 = const()[name = string("gather_6_cast_uint16_to_int32_dtype_0"), val = string("int32")];
            int32 concat_3_axis_0 = const()[name = string("concat_3_axis_0"), val = int32(0)];
            bool concat_3_interleave_0 = const()[name = string("concat_3_interleave_0"), val = bool(false)];
            int32 gather_6_cast_uint16_to_int32 = cast(dtype = gather_6_cast_uint16_to_int32_dtype_0, x = gather_6_cast_uint16)[name = string("cast_103")];
            int32 gather_5_cast_uint16_to_int32 = cast(dtype = gather_5_cast_uint16_to_int32_dtype_0, x = gather_5_cast_uint16)[name = string("cast_104")];
            tensor<int32, [4]> concat_3 = concat(axis = concat_3_axis_0, interleave = concat_3_interleave_0, values = (gather_5_cast_uint16_to_int32, gather_6_cast_uint16_to_int32, var_23, var_22))[name = string("concat_3")];
            tensor<fp16, [?, ?, 12, 32]> x_11_cast_fp16 = reshape(shape = concat_3, x = linear_0_cast_fp16)[name = string("x_11_cast_fp16")];
            bool attention_scores_1_transpose_x_0 = const()[name = string("attention_scores_1_transpose_x_0"), val = bool(false)];
            bool attention_scores_1_transpose_y_0 = const()[name = string("attention_scores_1_transpose_y_0"), val = bool(false)];
            tensor<int32, [4]> transpose_18_perm_0 = const()[name = string("transpose_18_perm_0"), val = tensor<int32, [4]>([0, 2, -3, -1])];
            tensor<int32, [4]> transpose_19_perm_0 = const()[name = string("transpose_19_perm_0"), val = tensor<int32, [4]>([0, 2, -1, -3])];
            tensor<fp16, [?, 12, 32, ?]> transpose_19 = transpose(perm = transpose_19_perm_0, x = x_3_cast_fp16)[name = string("transpose_51")];
            tensor<fp16, [?, 12, ?, 32]> transpose_18 = transpose(perm = transpose_18_perm_0, x = x_11_cast_fp16)[name = string("transpose_52")];
            tensor<fp16, [?, 12, ?, ?]> attention_scores_1_cast_fp16 = matmul(transpose_x = attention_scores_1_transpose_x_0, transpose_y = attention_scores_1_transpose_y_0, x = transpose_18, y = transpose_19)[name = string("attention_scores_1_cast_fp16")];
            fp16 _inversed_attention_scores_3_y_0_to_fp16 = const()[name = string("_inversed_attention_scores_3_y_0_to_fp16"), val = fp16(0x1.6ap-3)];
            tensor<fp16, [?, 12, ?, ?]> _inversed_attention_scores_3_cast_fp16 = mul(x = attention_scores_1_cast_fp16, y = _inversed_attention_scores_3_y_0_to_fp16)[name = string("_inversed_attention_scores_3_cast_fp16")];
            tensor<fp16, [?, 12, ?, ?]> input_11_cast_fp16 = add(x = _inversed_attention_scores_3_cast_fp16, y = attention_mask_cast_fp16)[name = string("input_11_cast_fp16")];
            tensor<fp16, [?, 12, ?, ?]> input_13_cast_fp16 = softmax(axis = var_24, x = input_11_cast_fp16)[name = string("input_13_cast_fp16")];
            bool context_layer_1_transpose_x_0 = const()[name = string("context_layer_1_transpose_x_0"), val = bool(false)];
            bool context_layer_1_transpose_y_0 = const()[name = string("context_layer_1_transpose_y_0"), val = bool(false)];
            tensor<fp16, [?, 12, ?, 32]> value_layer_1_cast_fp16 = transpose(perm = var_113, x = x_7_cast_fp16)[name = string("transpose_53")];
            tensor<fp16, [?, 12, ?, 32]> context_layer_1_cast_fp16 = matmul(transpose_x = context_layer_1_transpose_x_0, transpose_y = context_layer_1_transpose_y_0, x = input_13_cast_fp16, y = value_layer_1_cast_fp16)[name = string("context_layer_1_cast_fp16")];
            tensor<int32, [4]> var_129 = const()[name = string("op_129"), val = tensor<int32, [4]>([0, 2, 1, 3])];
            tensor<fp16, [?, ?, 12, 32]> var_130_cast_fp16 = transpose(perm = var_129, x = context_layer_1_cast_fp16)[name = string("transpose_50")];
            tensor<int32, [4]> var_132_shape_cast_fp16 = shape(x = var_130_cast_fp16)[name = string("op_132_shape_cast_fp16")];
            int32 gather_7_axis_0 = const()[name = string("gather_7_axis_0"), val = int32(0)];
            int32 gather_7_batch_dims_0 = const()[name = string("gather_7_batch_dims_0"), val = int32(0)];
            bool gather_7_validate_indices_0 = const()[name = string("gather_7_validate_indices_0"), val = bool(false)];
            string var_132_shape_cast_fp16_to_uint16_dtype_0 = const()[name = string("op_132_shape_cast_fp16_to_uint16_dtype_0"), val = string("uint16")];
            uint16 gather_7_indices_0_to_uint16 = const()[name = string("gather_7_indices_0_to_uint16"), val = uint16(0)];
            tensor<uint16, [4]> var_132_shape_cast_fp16_to_uint16 = cast(dtype = var_132_shape_cast_fp16_to_uint16_dtype_0, x = var_132_shape_cast_fp16)[name = string("cast_102")];
            uint16 gather_7_cast_uint16 = gather(axis = gather_7_axis_0, batch_dims = gather_7_batch_dims_0, indices = gather_7_indices_0_to_uint16, validate_indices = gather_7_validate_indices_0, x = var_132_shape_cast_fp16_to_uint16)[name = string("gather_7_cast_uint16")];
            string gather_7_cast_uint16_to_int32_dtype_0 = const()[name = string("gather_7_cast_uint16_to_int32_dtype_0"), val = string("int32")];
            int32 gather_8_axis_0 = const()[name = string("gather_8_axis_0"), val = int32(0)];
            int32 gather_8_batch_dims_0 = const()[name = string("gather_8_batch_dims_0"), val = int32(0)];
            bool gather_8_validate_indices_0 = const()[name = string("gather_8_validate_indices_0"), val = bool(false)];
            uint16 gather_8_indices_0_to_uint16 = const()[name = string("gather_8_indices_0_to_uint16"), val = uint16(1)];
            uint16 gather_8_cast_uint16 = gather(axis = gather_8_axis_0, batch_dims = gather_8_batch_dims_0, indices = gather_8_indices_0_to_uint16, validate_indices = gather_8_validate_indices_0, x = var_132_shape_cast_fp16_to_uint16)[name = string("gather_8_cast_uint16")];
            string gather_8_cast_uint16_to_int32_dtype_0 = const()[name = string("gather_8_cast_uint16_to_int32_dtype_0"), val = string("int32")];
            int32 concat_4_axis_0 = const()[name = string("concat_4_axis_0"), val = int32(0)];
            bool concat_4_interleave_0 = const()[name = string("concat_4_interleave_0"), val = bool(false)];
            int32 gather_8_cast_uint16_to_int32 = cast(dtype = gather_8_cast_uint16_to_int32_dtype_0, x = gather_8_cast_uint16)[name = string("cast_100")];
            int32 gather_7_cast_uint16_to_int32 = cast(dtype = gather_7_cast_uint16_to_int32_dtype_0, x = gather_7_cast_uint16)[name = string("cast_101")];
            tensor<int32, [3]> concat_4 = concat(axis = concat_4_axis_0, interleave = concat_4_interleave_0, values = (gather_7_cast_uint16_to_int32, gather_8_cast_uint16_to_int32, var_27))[name = string("concat_4")];
            tensor<fp16, [?, ?, 384]> input_15_cast_fp16 = reshape(shape = concat_4, x = var_130_cast_fp16)[name = string("input_15_cast_fp16")];
            tensor<fp16, [384, 384]> model_encoder_layer_0_attention_output_dense_weight_to_fp16 = const()[name = string("model_encoder_layer_0_attention_output_dense_weight_to_fp16"), val = tensor<fp16, [384, 384]>(BLOBFILE(path = string("@model_path/weights/weight.bin"), offset = uint64(24727104)))];
            tensor<fp16, [384]> model_encoder_layer_0_attention_output_dense_bias_to_fp16 = const()[name = string("model_encoder_layer_0_attention_output_dense_bias_to_fp16"), val = tensor<fp16, [384]>(BLOBFILE(path = string("@model_path/weights/weight.bin"), offset = uint64(25022080)))];
            tensor<fp16, [?, ?, 384]> linear_3_cast_fp16 = linear(bias = model_encoder_layer_0_attention_output_dense_bias_to_fp16, weight = model_encoder_layer_0_attention_output_dense_weight_to_fp16, x = input_15_cast_fp16)[name = string("linear_3_cast_fp16")];
            tensor<fp16, [?, ?, 384]> input_19_cast_fp16 = add(x = linear_3_cast_fp16, y = input_7_cast_fp16)[name = string("input_19_cast_fp16")];
            tensor<int32, [1]> input_21_axes_0 = const()[name = string("input_21_axes_0"), val = tensor<int32, [1]>([-1])];
            tensor<fp16, [384]> model_encoder_layer_0_attention_output_LayerNorm_weight_to_fp16 = const()[name = string("model_encoder_layer_0_attention_output_LayerNorm_weight_to_fp16"), val = tensor<fp16, [384]>(BLOBFILE(path = string("@model_path/weights/weight.bin"), offset = uint64(25022912)))];
            tensor<fp16, [384]> model_encoder_layer_0_attention_output_LayerNorm_bias_to_fp16 = const()[name = string("model_encoder_layer_0_attention_output_LayerNorm_bias_to_fp16"), val = tensor<fp16, [384]>(BLOBFILE(path = string("@model_path/weights/weight.bin"), offset = uint64(25023744)))];
            tensor<fp16, [?, ?, 384]> input_21_cast_fp16 = layer_norm(axes = input_21_axes_0, beta = model_encoder_layer_0_attention_output_LayerNorm_bias_to_fp16, epsilon = var_26_to_fp16, gamma = model_encoder_layer_0_attention_output_LayerNorm_weight_to_fp16, x = input_19_cast_fp16)[name = string("input_21_cast_fp16")];
            tensor<fp16, [1536, 384]> model_encoder_layer_0_intermediate_dense_weight_to_fp16 = const()[name = string("model_encoder_layer_0_intermediate_dense_weight_to_fp16"), val = tensor<fp16, [1536, 384]>(BLOBFILE(path = string("@model_path/weights/weight.bin"), offset = uint64(25024576)))];
            tensor<fp16, [1536]> model_encoder_layer_0_intermediate_dense_bias_to_fp16 = const()[name = string("model_encoder_layer_0_intermediate_dense_bias_to_fp16"), val = tensor<fp16, [1536]>(BLOBFILE(path = string("@model_path/weights/weight.bin"), offset = uint64(26204288)))];
            tensor<fp16, [?, ?, 1536]> linear_4_cast_fp16 = linear(bias = model_encoder_layer_0_intermediate_dense_bias_to_fp16, weight = model_encoder_layer_0_intermediate_dense_weight_to_fp16, x = input_21_cast_fp16)[name = string("linear_4_cast_fp16")];
            string input_25_mode_0 = const()[name = string("input_25_mode_0"), val = string("EXACT")];
            tensor<fp16, [?, ?, 1536]> input_25_cast_fp16 = gelu(mode = input_25_mode_0, x = linear_4_cast_fp16)[name = string("input_25_cast_fp16")];
            tensor<fp16, [384, 1536]> model_encoder_layer_0_output_dense_weight_to_fp16 = const()[name = string("model_encoder_layer_0_output_dense_weight_to_fp16"), val = tensor<fp16, [384, 1536]>(BLOBFILE(path = string("@model_path/weights/weight.bin"), offset = uint64(26207424)))];
            tensor<fp16, [384]> model_encoder_layer_0_output_dense_bias_to_fp16 = const()[name = string("model_encoder_layer_0_output_dense_bias_to_fp16"), val = tensor<fp16, [384]>(BLOBFILE(path = string("@model_path/weights/weight.bin"), offset = uint64(27387136)))];
            tensor<fp16, [?, ?, 384]> linear_5_cast_fp16 = linear(bias = model_encoder_layer_0_output_dense_bias_to_fp16, weight = model_encoder_layer_0_output_dense_weight_to_fp16, x = input_25_cast_fp16)[name = string("linear_5_cast_fp16")];
            tensor<fp16, [?, ?, 384]> input_29_cast_fp16 = add(x = linear_5_cast_fp16, y = input_21_cast_fp16)[name = string("input_29_cast_fp16")];
            tensor<int32, [1]> input_31_axes_0 = const()[name = string("input_31_axes_0"), val = tensor<int32, [1]>([-1])];
            tensor<fp16, [384]> model_encoder_layer_0_output_LayerNorm_weight_to_fp16 = const()[name = string("model_encoder_layer_0_output_LayerNorm_weight_to_fp16"), val = tensor<fp16, [384]>(BLOBFILE(path = string("@model_path/weights/weight.bin"), offset = uint64(27387968)))];
            tensor<fp16, [384]> model_encoder_layer_0_output_LayerNorm_bias_to_fp16 = const()[name = string("model_encoder_layer_0_output_LayerNorm_bias_to_fp16"), val = tensor<fp16, [384]>(BLOBFILE(path = string("@model_path/weights/weight.bin"), offset = uint64(27388800)))];
            tensor<fp16, [?, ?, 384]> input_31_cast_fp16 = layer_norm(axes = input_31_axes_0, beta = model_encoder_layer_0_output_LayerNorm_bias_to_fp16, epsilon = var_26_to_fp16, gamma = model_encoder_layer_0_output_LayerNorm_weight_to_fp16, x = input_29_cast_fp16)[name = string("input_31_cast_fp16")];
            tensor<fp16, [384, 384]> model_encoder_layer_1_attention_self_query_weight_to_fp16 = const()[name = string("model_encoder_layer_1_attention_self_query_weight_to_fp16"), val = tensor<fp16, [384, 384]>(BLOBFILE(path = string("@model_path/weights/weight.bin"), offset = uint64(27389632)))];
            tensor<fp16, [384]> model_encoder_layer_1_attention_self_query_bias_to_fp16 = const()[name = string("model_encoder_layer_1_attention_self_query_bias_to_fp16"), val = tensor<fp16, [384]>(BLOBFILE(path = string("@model_path/weights/weight.bin"), offset = uint64(27684608)))];
            tensor<fp16, [?, ?, 384]> linear_6_cast_fp16 = linear(bias = model_encoder_layer_1_attention_self_query_bias_to_fp16, weight = model_encoder_layer_1_attention_self_query_weight_to_fp16, x = input_31_cast_fp16)[name = string("linear_6_cast_fp16")];
            tensor<fp16, [384, 384]> model_encoder_layer_1_attention_self_key_weight_to_fp16 = const()[name = string("model_encoder_layer_1_attention_self_key_weight_to_fp16"), val = tensor<fp16, [384, 384]>(BLOBFILE(path = string("@model_path/weights/weight.bin"), offset = uint64(27685440)))];
            tensor<fp16, [384]> model_encoder_layer_1_attention_self_key_bias_to_fp16 = const()[name = string("model_encoder_layer_1_attention_self_key_bias_to_fp16"), val = tensor<fp16, [384]>(BLOBFILE(path = string("@model_path/weights/weight.bin"), offset = uint64(27980416)))];
            tensor<fp16, [?, ?, 384]> linear_7_cast_fp16 = linear(bias = model_encoder_layer_1_attention_self_key_bias_to_fp16, weight = model_encoder_layer_1_attention_self_key_weight_to_fp16, x = input_31_cast_fp16)[name = string("linear_7_cast_fp16")];
            tensor<int32, [3]> var_177_shape_cast_fp16 = shape(x = linear_7_cast_fp16)[name = string("op_177_shape_cast_fp16")];
            int32 gather_9_axis_0 = const()[name = string("gather_9_axis_0"), val = int32(0)];
            int32 gather_9_batch_dims_0 = const()[name = string("gather_9_batch_dims_0"), val = int32(0)];
            bool gather_9_validate_indices_0 = const()[name = string("gather_9_validate_indices_0"), val = bool(false)];
            string var_177_shape_cast_fp16_to_uint16_dtype_0 = const()[name = string("op_177_shape_cast_fp16_to_uint16_dtype_0"), val = string("uint16")];
            uint16 gather_9_indices_0_to_uint16 = const()[name = string("gather_9_indices_0_to_uint16"), val = uint16(0)];
            tensor<uint16, [3]> var_177_shape_cast_fp16_to_uint16 = cast(dtype = var_177_shape_cast_fp16_to_uint16_dtype_0, x = var_177_shape_cast_fp16)[name = string("cast_99")];
            uint16 gather_9_cast_uint16 = gather(axis = gather_9_axis_0, batch_dims = gather_9_batch_dims_0, indices = gather_9_indices_0_to_uint16, validate_indices = gather_9_validate_indices_0, x = var_177_shape_cast_fp16_to_uint16)[name = string("gather_9_cast_uint16")];
            string gather_9_cast_uint16_to_int32_dtype_0 = const()[name = string("gather_9_cast_uint16_to_int32_dtype_0"), val = string("int32")];
            int32 gather_10_axis_0 = const()[name = string("gather_10_axis_0"), val = int32(0)];
            int32 gather_10_batch_dims_0 = const()[name = string("gather_10_batch_dims_0"), val = int32(0)];
            bool gather_10_validate_indices_0 = const()[name = string("gather_10_validate_indices_0"), val = bool(false)];
            uint16 gather_10_indices_0_to_uint16 = const()[name = string("gather_10_indices_0_to_uint16"), val = uint16(1)];
            uint16 gather_10_cast_uint16 = gather(axis = gather_10_axis_0, batch_dims = gather_10_batch_dims_0, indices = gather_10_indices_0_to_uint16, validate_indices = gather_10_validate_indices_0, x = var_177_shape_cast_fp16_to_uint16)[name = string("gather_10_cast_uint16")];
            string gather_10_cast_uint16_to_int32_dtype_0 = const()[name = string("gather_10_cast_uint16_to_int32_dtype_0"), val = string("int32")];
            int32 concat_5_axis_0 = const()[name = string("concat_5_axis_0"), val = int32(0)];
            bool concat_5_interleave_0 = const()[name = string("concat_5_interleave_0"), val = bool(false)];
            int32 gather_10_cast_uint16_to_int32 = cast(dtype = gather_10_cast_uint16_to_int32_dtype_0, x = gather_10_cast_uint16)[name = string("cast_97")];
            int32 gather_9_cast_uint16_to_int32 = cast(dtype = gather_9_cast_uint16_to_int32_dtype_0, x = gather_9_cast_uint16)[name = string("cast_98")];
            tensor<int32, [4]> concat_5 = concat(axis = concat_5_axis_0, interleave = concat_5_interleave_0, values = (gather_9_cast_uint16_to_int32, gather_10_cast_uint16_to_int32, var_23, var_22))[name = string("concat_5")];
            tensor<fp16, [?, ?, 12, 32]> x_15_cast_fp16 = reshape(shape = concat_5, x = linear_7_cast_fp16)[name = string("x_15_cast_fp16")];
            tensor<fp16, [384, 384]> model_encoder_layer_1_attention_self_value_weight_to_fp16 = const()[name = string("model_encoder_layer_1_attention_self_value_weight_to_fp16"), val = tensor<fp16, [384, 384]>(BLOBFILE(path = string("@model_path/weights/weight.bin"), offset = uint64(27981248)))];
            tensor<fp16, [384]> model_encoder_layer_1_attention_self_value_bias_to_fp16 = const()[name = string("model_encoder_layer_1_attention_self_value_bias_to_fp16"), val = tensor<fp16, [384]>(BLOBFILE(path = string("@model_path/weights/weight.bin"), offset = uint64(28276224)))];
            tensor<fp16, [?, ?, 384]> linear_8_cast_fp16 = linear(bias = model_encoder_layer_1_attention_self_value_bias_to_fp16, weight = model_encoder_layer_1_attention_self_value_weight_to_fp16, x = input_31_cast_fp16)[name = string("linear_8_cast_fp16")];
            tensor<int32, [3]> var_186_shape_cast_fp16 = shape(x = linear_8_cast_fp16)[name = string("op_186_shape_cast_fp16")];
            int32 gather_11_axis_0 = const()[name = string("gather_11_axis_0"), val = int32(0)];
            int32 gather_11_batch_dims_0 = const()[name = string("gather_11_batch_dims_0"), val = int32(0)];
            bool gather_11_validate_indices_0 = const()[name = string("gather_11_validate_indices_0"), val = bool(false)];
            string var_186_shape_cast_fp16_to_uint16_dtype_0 = const()[name = string("op_186_shape_cast_fp16_to_uint16_dtype_0"), val = string("uint16")];
            uint16 gather_11_indices_0_to_uint16 = const()[name = string("gather_11_indices_0_to_uint16"), val = uint16(0)];
            tensor<uint16, [3]> var_186_shape_cast_fp16_to_uint16 = cast(dtype = var_186_shape_cast_fp16_to_uint16_dtype_0, x = var_186_shape_cast_fp16)[name = string("cast_96")];
            uint16 gather_11_cast_uint16 = gather(axis = gather_11_axis_0, batch_dims = gather_11_batch_dims_0, indices = gather_11_indices_0_to_uint16, validate_indices = gather_11_validate_indices_0, x = var_186_shape_cast_fp16_to_uint16)[name = string("gather_11_cast_uint16")];
            string gather_11_cast_uint16_to_int32_dtype_0 = const()[name = string("gather_11_cast_uint16_to_int32_dtype_0"), val = string("int32")];
            int32 gather_12_axis_0 = const()[name = string("gather_12_axis_0"), val = int32(0)];
            int32 gather_12_batch_dims_0 = const()[name = string("gather_12_batch_dims_0"), val = int32(0)];
            bool gather_12_validate_indices_0 = const()[name = string("gather_12_validate_indices_0"), val = bool(false)];
            uint16 gather_12_indices_0_to_uint16 = const()[name = string("gather_12_indices_0_to_uint16"), val = uint16(1)];
            uint16 gather_12_cast_uint16 = gather(axis = gather_12_axis_0, batch_dims = gather_12_batch_dims_0, indices = gather_12_indices_0_to_uint16, validate_indices = gather_12_validate_indices_0, x = var_186_shape_cast_fp16_to_uint16)[name = string("gather_12_cast_uint16")];
            string gather_12_cast_uint16_to_int32_dtype_0 = const()[name = string("gather_12_cast_uint16_to_int32_dtype_0"), val = string("int32")];
            int32 concat_6_axis_0 = const()[name = string("concat_6_axis_0"), val = int32(0)];
            bool concat_6_interleave_0 = const()[name = string("concat_6_interleave_0"), val = bool(false)];
            int32 gather_12_cast_uint16_to_int32 = cast(dtype = gather_12_cast_uint16_to_int32_dtype_0, x = gather_12_cast_uint16)[name = string("cast_94")];
            int32 gather_11_cast_uint16_to_int32 = cast(dtype = gather_11_cast_uint16_to_int32_dtype_0, x = gather_11_cast_uint16)[name = string("cast_95")];
            tensor<int32, [4]> concat_6 = concat(axis = concat_6_axis_0, interleave = concat_6_interleave_0, values = (gather_11_cast_uint16_to_int32, gather_12_cast_uint16_to_int32, var_23, var_22))[name = string("concat_6")];
            tensor<fp16, [?, ?, 12, 32]> x_19_cast_fp16 = reshape(shape = concat_6, x = linear_8_cast_fp16)[name = string("x_19_cast_fp16")];
            tensor<int32, [4]> var_190 = const()[name = string("op_190"), val = tensor<int32, [4]>([0, 2, 1, 3])];
            tensor<int32, [3]> var_192_shape_cast_fp16 = shape(x = linear_6_cast_fp16)[name = string("op_192_shape_cast_fp16")];
            int32 gather_13_axis_0 = const()[name = string("gather_13_axis_0"), val = int32(0)];
            int32 gather_13_batch_dims_0 = const()[name = string("gather_13_batch_dims_0"), val = int32(0)];
            bool gather_13_validate_indices_0 = const()[name = string("gather_13_validate_indices_0"), val = bool(false)];
            string var_192_shape_cast_fp16_to_uint16_dtype_0 = const()[name = string("op_192_shape_cast_fp16_to_uint16_dtype_0"), val = string("uint16")];
            uint16 gather_13_indices_0_to_uint16 = const()[name = string("gather_13_indices_0_to_uint16"), val = uint16(0)];
            tensor<uint16, [3]> var_192_shape_cast_fp16_to_uint16 = cast(dtype = var_192_shape_cast_fp16_to_uint16_dtype_0, x = var_192_shape_cast_fp16)[name = string("cast_93")];
            uint16 gather_13_cast_uint16 = gather(axis = gather_13_axis_0, batch_dims = gather_13_batch_dims_0, indices = gather_13_indices_0_to_uint16, validate_indices = gather_13_validate_indices_0, x = var_192_shape_cast_fp16_to_uint16)[name = string("gather_13_cast_uint16")];
            string gather_13_cast_uint16_to_int32_dtype_0 = const()[name = string("gather_13_cast_uint16_to_int32_dtype_0"), val = string("int32")];
            int32 gather_14_axis_0 = const()[name = string("gather_14_axis_0"), val = int32(0)];
            int32 gather_14_batch_dims_0 = const()[name = string("gather_14_batch_dims_0"), val = int32(0)];
            bool gather_14_validate_indices_0 = const()[name = string("gather_14_validate_indices_0"), val = bool(false)];
            uint16 gather_14_indices_0_to_uint16 = const()[name = string("gather_14_indices_0_to_uint16"), val = uint16(1)];
            uint16 gather_14_cast_uint16 = gather(axis = gather_14_axis_0, batch_dims = gather_14_batch_dims_0, indices = gather_14_indices_0_to_uint16, validate_indices = gather_14_validate_indices_0, x = var_192_shape_cast_fp16_to_uint16)[name = string("gather_14_cast_uint16")];
            string gather_14_cast_uint16_to_int32_dtype_0 = const()[name = string("gather_14_cast_uint16_to_int32_dtype_0"), val = string("int32")];
            int32 concat_7_axis_0 = const()[name = string("concat_7_axis_0"), val = int32(0)];
            bool concat_7_interleave_0 = const()[name = string("concat_7_interleave_0"), val = bool(false)];
            int32 gather_14_cast_uint16_to_int32 = cast(dtype = gather_14_cast_uint16_to_int32_dtype_0, x = gather_14_cast_uint16)[name = string("cast_91")];
            int32 gather_13_cast_uint16_to_int32 = cast(dtype = gather_13_cast_uint16_to_int32_dtype_0, x = gather_13_cast_uint16)[name = string("cast_92")];
            tensor<int32, [4]> concat_7 = concat(axis = concat_7_axis_0, interleave = concat_7_interleave_0, values = (gather_13_cast_uint16_to_int32, gather_14_cast_uint16_to_int32, var_23, var_22))[name = string("concat_7")];
            tensor<fp16, [?, ?, 12, 32]> x_23_cast_fp16 = reshape(shape = concat_7, x = linear_6_cast_fp16)[name = string("x_23_cast_fp16")];
            bool attention_scores_5_transpose_x_0 = const()[name = string("attention_scores_5_transpose_x_0"), val = bool(false)];
            bool attention_scores_5_transpose_y_0 = const()[name = string("attention_scores_5_transpose_y_0"), val = bool(false)];
            tensor<int32, [4]> transpose_20_perm_0 = const()[name = string("transpose_20_perm_0"), val = tensor<int32, [4]>([0, 2, -3, -1])];
            tensor<int32, [4]> transpose_21_perm_0 = const()[name = string("transpose_21_perm_0"), val = tensor<int32, [4]>([0, 2, -1, -3])];
            tensor<fp16, [?, 12, 32, ?]> transpose_21 = transpose(perm = transpose_21_perm_0, x = x_15_cast_fp16)[name = string("transpose_47")];
            tensor<fp16, [?, 12, ?, 32]> transpose_20 = transpose(perm = transpose_20_perm_0, x = x_23_cast_fp16)[name = string("transpose_48")];
            tensor<fp16, [?, 12, ?, ?]> attention_scores_5_cast_fp16 = matmul(transpose_x = attention_scores_5_transpose_x_0, transpose_y = attention_scores_5_transpose_y_0, x = transpose_20, y = transpose_21)[name = string("attention_scores_5_cast_fp16")];
            fp16 _inversed_attention_scores_7_y_0_to_fp16 = const()[name = string("_inversed_attention_scores_7_y_0_to_fp16"), val = fp16(0x1.6ap-3)];
            tensor<fp16, [?, 12, ?, ?]> _inversed_attention_scores_7_cast_fp16 = mul(x = attention_scores_5_cast_fp16, y = _inversed_attention_scores_7_y_0_to_fp16)[name = string("_inversed_attention_scores_7_cast_fp16")];
            tensor<fp16, [?, 12, ?, ?]> input_33_cast_fp16 = add(x = _inversed_attention_scores_7_cast_fp16, y = attention_mask_cast_fp16)[name = string("input_33_cast_fp16")];
            tensor<fp16, [?, 12, ?, ?]> input_35_cast_fp16 = softmax(axis = var_24, x = input_33_cast_fp16)[name = string("input_35_cast_fp16")];
            bool context_layer_5_transpose_x_0 = const()[name = string("context_layer_5_transpose_x_0"), val = bool(false)];
            bool context_layer_5_transpose_y_0 = const()[name = string("context_layer_5_transpose_y_0"), val = bool(false)];
            tensor<fp16, [?, 12, ?, 32]> value_layer_3_cast_fp16 = transpose(perm = var_190, x = x_19_cast_fp16)[name = string("transpose_49")];
            tensor<fp16, [?, 12, ?, 32]> context_layer_5_cast_fp16 = matmul(transpose_x = context_layer_5_transpose_x_0, transpose_y = context_layer_5_transpose_y_0, x = input_35_cast_fp16, y = value_layer_3_cast_fp16)[name = string("context_layer_5_cast_fp16")];
            tensor<int32, [4]> var_206 = const()[name = string("op_206"), val = tensor<int32, [4]>([0, 2, 1, 3])];
            tensor<fp16, [?, ?, 12, 32]> var_207_cast_fp16 = transpose(perm = var_206, x = context_layer_5_cast_fp16)[name = string("transpose_46")];
            tensor<int32, [4]> var_209_shape_cast_fp16 = shape(x = var_207_cast_fp16)[name = string("op_209_shape_cast_fp16")];
            int32 gather_15_axis_0 = const()[name = string("gather_15_axis_0"), val = int32(0)];
            int32 gather_15_batch_dims_0 = const()[name = string("gather_15_batch_dims_0"), val = int32(0)];
            bool gather_15_validate_indices_0 = const()[name = string("gather_15_validate_indices_0"), val = bool(false)];
            string var_209_shape_cast_fp16_to_uint16_dtype_0 = const()[name = string("op_209_shape_cast_fp16_to_uint16_dtype_0"), val = string("uint16")];
            uint16 gather_15_indices_0_to_uint16 = const()[name = string("gather_15_indices_0_to_uint16"), val = uint16(0)];
            tensor<uint16, [4]> var_209_shape_cast_fp16_to_uint16 = cast(dtype = var_209_shape_cast_fp16_to_uint16_dtype_0, x = var_209_shape_cast_fp16)[name = string("cast_90")];
            uint16 gather_15_cast_uint16 = gather(axis = gather_15_axis_0, batch_dims = gather_15_batch_dims_0, indices = gather_15_indices_0_to_uint16, validate_indices = gather_15_validate_indices_0, x = var_209_shape_cast_fp16_to_uint16)[name = string("gather_15_cast_uint16")];
            string gather_15_cast_uint16_to_int32_dtype_0 = const()[name = string("gather_15_cast_uint16_to_int32_dtype_0"), val = string("int32")];
            int32 gather_16_axis_0 = const()[name = string("gather_16_axis_0"), val = int32(0)];
            int32 gather_16_batch_dims_0 = const()[name = string("gather_16_batch_dims_0"), val = int32(0)];
            bool gather_16_validate_indices_0 = const()[name = string("gather_16_validate_indices_0"), val = bool(false)];
            uint16 gather_16_indices_0_to_uint16 = const()[name = string("gather_16_indices_0_to_uint16"), val = uint16(1)];
            uint16 gather_16_cast_uint16 = gather(axis = gather_16_axis_0, batch_dims = gather_16_batch_dims_0, indices = gather_16_indices_0_to_uint16, validate_indices = gather_16_validate_indices_0, x = var_209_shape_cast_fp16_to_uint16)[name = string("gather_16_cast_uint16")];
            string gather_16_cast_uint16_to_int32_dtype_0 = const()[name = string("gather_16_cast_uint16_to_int32_dtype_0"), val = string("int32")];
            int32 concat_8_axis_0 = const()[name = string("concat_8_axis_0"), val = int32(0)];
            bool concat_8_interleave_0 = const()[name = string("concat_8_interleave_0"), val = bool(false)];
            int32 gather_16_cast_uint16_to_int32 = cast(dtype = gather_16_cast_uint16_to_int32_dtype_0, x = gather_16_cast_uint16)[name = string("cast_88")];
            int32 gather_15_cast_uint16_to_int32 = cast(dtype = gather_15_cast_uint16_to_int32_dtype_0, x = gather_15_cast_uint16)[name = string("cast_89")];
            tensor<int32, [3]> concat_8 = concat(axis = concat_8_axis_0, interleave = concat_8_interleave_0, values = (gather_15_cast_uint16_to_int32, gather_16_cast_uint16_to_int32, var_27))[name = string("concat_8")];
            tensor<fp16, [?, ?, 384]> input_37_cast_fp16 = reshape(shape = concat_8, x = var_207_cast_fp16)[name = string("input_37_cast_fp16")];
            tensor<fp16, [384, 384]> model_encoder_layer_1_attention_output_dense_weight_to_fp16 = const()[name = string("model_encoder_layer_1_attention_output_dense_weight_to_fp16"), val = tensor<fp16, [384, 384]>(BLOBFILE(path = string("@model_path/weights/weight.bin"), offset = uint64(28277056)))];
            tensor<fp16, [384]> model_encoder_layer_1_attention_output_dense_bias_to_fp16 = const()[name = string("model_encoder_layer_1_attention_output_dense_bias_to_fp16"), val = tensor<fp16, [384]>(BLOBFILE(path = string("@model_path/weights/weight.bin"), offset = uint64(28572032)))];
            tensor<fp16, [?, ?, 384]> linear_9_cast_fp16 = linear(bias = model_encoder_layer_1_attention_output_dense_bias_to_fp16, weight = model_encoder_layer_1_attention_output_dense_weight_to_fp16, x = input_37_cast_fp16)[name = string("linear_9_cast_fp16")];
            tensor<fp16, [?, ?, 384]> input_41_cast_fp16 = add(x = linear_9_cast_fp16, y = input_31_cast_fp16)[name = string("input_41_cast_fp16")];
            tensor<int32, [1]> input_43_axes_0 = const()[name = string("input_43_axes_0"), val = tensor<int32, [1]>([-1])];
            tensor<fp16, [384]> model_encoder_layer_1_attention_output_LayerNorm_weight_to_fp16 = const()[name = string("model_encoder_layer_1_attention_output_LayerNorm_weight_to_fp16"), val = tensor<fp16, [384]>(BLOBFILE(path = string("@model_path/weights/weight.bin"), offset = uint64(28572864)))];
            tensor<fp16, [384]> model_encoder_layer_1_attention_output_LayerNorm_bias_to_fp16 = const()[name = string("model_encoder_layer_1_attention_output_LayerNorm_bias_to_fp16"), val = tensor<fp16, [384]>(BLOBFILE(path = string("@model_path/weights/weight.bin"), offset = uint64(28573696)))];
            tensor<fp16, [?, ?, 384]> input_43_cast_fp16 = layer_norm(axes = input_43_axes_0, beta = model_encoder_layer_1_attention_output_LayerNorm_bias_to_fp16, epsilon = var_26_to_fp16, gamma = model_encoder_layer_1_attention_output_LayerNorm_weight_to_fp16, x = input_41_cast_fp16)[name = string("input_43_cast_fp16")];
            tensor<fp16, [1536, 384]> model_encoder_layer_1_intermediate_dense_weight_to_fp16 = const()[name = string("model_encoder_layer_1_intermediate_dense_weight_to_fp16"), val = tensor<fp16, [1536, 384]>(BLOBFILE(path = string("@model_path/weights/weight.bin"), offset = uint64(28574528)))];
            tensor<fp16, [1536]> model_encoder_layer_1_intermediate_dense_bias_to_fp16 = const()[name = string("model_encoder_layer_1_intermediate_dense_bias_to_fp16"), val = tensor<fp16, [1536]>(BLOBFILE(path = string("@model_path/weights/weight.bin"), offset = uint64(29754240)))];
            tensor<fp16, [?, ?, 1536]> linear_10_cast_fp16 = linear(bias = model_encoder_layer_1_intermediate_dense_bias_to_fp16, weight = model_encoder_layer_1_intermediate_dense_weight_to_fp16, x = input_43_cast_fp16)[name = string("linear_10_cast_fp16")];
            string input_47_mode_0 = const()[name = string("input_47_mode_0"), val = string("EXACT")];
            tensor<fp16, [?, ?, 1536]> input_47_cast_fp16 = gelu(mode = input_47_mode_0, x = linear_10_cast_fp16)[name = string("input_47_cast_fp16")];
            tensor<fp16, [384, 1536]> model_encoder_layer_1_output_dense_weight_to_fp16 = const()[name = string("model_encoder_layer_1_output_dense_weight_to_fp16"), val = tensor<fp16, [384, 1536]>(BLOBFILE(path = string("@model_path/weights/weight.bin"), offset = uint64(29757376)))];
            tensor<fp16, [384]> model_encoder_layer_1_output_dense_bias_to_fp16 = const()[name = string("model_encoder_layer_1_output_dense_bias_to_fp16"), val = tensor<fp16, [384]>(BLOBFILE(path = string("@model_path/weights/weight.bin"), offset = uint64(30937088)))];
            tensor<fp16, [?, ?, 384]> linear_11_cast_fp16 = linear(bias = model_encoder_layer_1_output_dense_bias_to_fp16, weight = model_encoder_layer_1_output_dense_weight_to_fp16, x = input_47_cast_fp16)[name = string("linear_11_cast_fp16")];
            tensor<fp16, [?, ?, 384]> input_51_cast_fp16 = add(x = linear_11_cast_fp16, y = input_43_cast_fp16)[name = string("input_51_cast_fp16")];
            tensor<int32, [1]> input_53_axes_0 = const()[name = string("input_53_axes_0"), val = tensor<int32, [1]>([-1])];
            tensor<fp16, [384]> model_encoder_layer_1_output_LayerNorm_weight_to_fp16 = const()[name = string("model_encoder_layer_1_output_LayerNorm_weight_to_fp16"), val = tensor<fp16, [384]>(BLOBFILE(path = string("@model_path/weights/weight.bin"), offset = uint64(30937920)))];
            tensor<fp16, [384]> model_encoder_layer_1_output_LayerNorm_bias_to_fp16 = const()[name = string("model_encoder_layer_1_output_LayerNorm_bias_to_fp16"), val = tensor<fp16, [384]>(BLOBFILE(path = string("@model_path/weights/weight.bin"), offset = uint64(30938752)))];
            tensor<fp16, [?, ?, 384]> input_53_cast_fp16 = layer_norm(axes = input_53_axes_0, beta = model_encoder_layer_1_output_LayerNorm_bias_to_fp16, epsilon = var_26_to_fp16, gamma = model_encoder_layer_1_output_LayerNorm_weight_to_fp16, x = input_51_cast_fp16)[name = string("input_53_cast_fp16")];
            tensor<fp16, [384, 384]> model_encoder_layer_2_attention_self_query_weight_to_fp16 = const()[name = string("model_encoder_layer_2_attention_self_query_weight_to_fp16"), val = tensor<fp16, [384, 384]>(BLOBFILE(path = string("@model_path/weights/weight.bin"), offset = uint64(30939584)))];
            tensor<fp16, [384]> model_encoder_layer_2_attention_self_query_bias_to_fp16 = const()[name = string("model_encoder_layer_2_attention_self_query_bias_to_fp16"), val = tensor<fp16, [384]>(BLOBFILE(path = string("@model_path/weights/weight.bin"), offset = uint64(31234560)))];
            tensor<fp16, [?, ?, 384]> linear_12_cast_fp16 = linear(bias = model_encoder_layer_2_attention_self_query_bias_to_fp16, weight = model_encoder_layer_2_attention_self_query_weight_to_fp16, x = input_53_cast_fp16)[name = string("linear_12_cast_fp16")];
            tensor<fp16, [384, 384]> model_encoder_layer_2_attention_self_key_weight_to_fp16 = const()[name = string("model_encoder_layer_2_attention_self_key_weight_to_fp16"), val = tensor<fp16, [384, 384]>(BLOBFILE(path = string("@model_path/weights/weight.bin"), offset = uint64(31235392)))];
            tensor<fp16, [384]> model_encoder_layer_2_attention_self_key_bias_to_fp16 = const()[name = string("model_encoder_layer_2_attention_self_key_bias_to_fp16"), val = tensor<fp16, [384]>(BLOBFILE(path = string("@model_path/weights/weight.bin"), offset = uint64(31530368)))];
            tensor<fp16, [?, ?, 384]> linear_13_cast_fp16 = linear(bias = model_encoder_layer_2_attention_self_key_bias_to_fp16, weight = model_encoder_layer_2_attention_self_key_weight_to_fp16, x = input_53_cast_fp16)[name = string("linear_13_cast_fp16")];
            tensor<int32, [3]> var_254_shape_cast_fp16 = shape(x = linear_13_cast_fp16)[name = string("op_254_shape_cast_fp16")];
            int32 gather_17_axis_0 = const()[name = string("gather_17_axis_0"), val = int32(0)];
            int32 gather_17_batch_dims_0 = const()[name = string("gather_17_batch_dims_0"), val = int32(0)];
            bool gather_17_validate_indices_0 = const()[name = string("gather_17_validate_indices_0"), val = bool(false)];
            string var_254_shape_cast_fp16_to_uint16_dtype_0 = const()[name = string("op_254_shape_cast_fp16_to_uint16_dtype_0"), val = string("uint16")];
            uint16 gather_17_indices_0_to_uint16 = const()[name = string("gather_17_indices_0_to_uint16"), val = uint16(0)];
            tensor<uint16, [3]> var_254_shape_cast_fp16_to_uint16 = cast(dtype = var_254_shape_cast_fp16_to_uint16_dtype_0, x = var_254_shape_cast_fp16)[name = string("cast_87")];
            uint16 gather_17_cast_uint16 = gather(axis = gather_17_axis_0, batch_dims = gather_17_batch_dims_0, indices = gather_17_indices_0_to_uint16, validate_indices = gather_17_validate_indices_0, x = var_254_shape_cast_fp16_to_uint16)[name = string("gather_17_cast_uint16")];
            string gather_17_cast_uint16_to_int32_dtype_0 = const()[name = string("gather_17_cast_uint16_to_int32_dtype_0"), val = string("int32")];
            int32 gather_18_axis_0 = const()[name = string("gather_18_axis_0"), val = int32(0)];
            int32 gather_18_batch_dims_0 = const()[name = string("gather_18_batch_dims_0"), val = int32(0)];
            bool gather_18_validate_indices_0 = const()[name = string("gather_18_validate_indices_0"), val = bool(false)];
            uint16 gather_18_indices_0_to_uint16 = const()[name = string("gather_18_indices_0_to_uint16"), val = uint16(1)];
            uint16 gather_18_cast_uint16 = gather(axis = gather_18_axis_0, batch_dims = gather_18_batch_dims_0, indices = gather_18_indices_0_to_uint16, validate_indices = gather_18_validate_indices_0, x = var_254_shape_cast_fp16_to_uint16)[name = string("gather_18_cast_uint16")];
            string gather_18_cast_uint16_to_int32_dtype_0 = const()[name = string("gather_18_cast_uint16_to_int32_dtype_0"), val = string("int32")];
            int32 concat_9_axis_0 = const()[name = string("concat_9_axis_0"), val = int32(0)];
            bool concat_9_interleave_0 = const()[name = string("concat_9_interleave_0"), val = bool(false)];
            int32 gather_18_cast_uint16_to_int32 = cast(dtype = gather_18_cast_uint16_to_int32_dtype_0, x = gather_18_cast_uint16)[name = string("cast_85")];
            int32 gather_17_cast_uint16_to_int32 = cast(dtype = gather_17_cast_uint16_to_int32_dtype_0, x = gather_17_cast_uint16)[name = string("cast_86")];
            tensor<int32, [4]> concat_9 = concat(axis = concat_9_axis_0, interleave = concat_9_interleave_0, values = (gather_17_cast_uint16_to_int32, gather_18_cast_uint16_to_int32, var_23, var_22))[name = string("concat_9")];
            tensor<fp16, [?, ?, 12, 32]> x_27_cast_fp16 = reshape(shape = concat_9, x = linear_13_cast_fp16)[name = string("x_27_cast_fp16")];
            tensor<fp16, [384, 384]> model_encoder_layer_2_attention_self_value_weight_to_fp16 = const()[name = string("model_encoder_layer_2_attention_self_value_weight_to_fp16"), val = tensor<fp16, [384, 384]>(BLOBFILE(path = string("@model_path/weights/weight.bin"), offset = uint64(31531200)))];
            tensor<fp16, [384]> model_encoder_layer_2_attention_self_value_bias_to_fp16 = const()[name = string("model_encoder_layer_2_attention_self_value_bias_to_fp16"), val = tensor<fp16, [384]>(BLOBFILE(path = string("@model_path/weights/weight.bin"), offset = uint64(31826176)))];
            tensor<fp16, [?, ?, 384]> linear_14_cast_fp16 = linear(bias = model_encoder_layer_2_attention_self_value_bias_to_fp16, weight = model_encoder_layer_2_attention_self_value_weight_to_fp16, x = input_53_cast_fp16)[name = string("linear_14_cast_fp16")];
            tensor<int32, [3]> var_263_shape_cast_fp16 = shape(x = linear_14_cast_fp16)[name = string("op_263_shape_cast_fp16")];
            int32 gather_19_axis_0 = const()[name = string("gather_19_axis_0"), val = int32(0)];
            int32 gather_19_batch_dims_0 = const()[name = string("gather_19_batch_dims_0"), val = int32(0)];
            bool gather_19_validate_indices_0 = const()[name = string("gather_19_validate_indices_0"), val = bool(false)];
            string var_263_shape_cast_fp16_to_uint16_dtype_0 = const()[name = string("op_263_shape_cast_fp16_to_uint16_dtype_0"), val = string("uint16")];
            uint16 gather_19_indices_0_to_uint16 = const()[name = string("gather_19_indices_0_to_uint16"), val = uint16(0)];
            tensor<uint16, [3]> var_263_shape_cast_fp16_to_uint16 = cast(dtype = var_263_shape_cast_fp16_to_uint16_dtype_0, x = var_263_shape_cast_fp16)[name = string("cast_84")];
            uint16 gather_19_cast_uint16 = gather(axis = gather_19_axis_0, batch_dims = gather_19_batch_dims_0, indices = gather_19_indices_0_to_uint16, validate_indices = gather_19_validate_indices_0, x = var_263_shape_cast_fp16_to_uint16)[name = string("gather_19_cast_uint16")];
            string gather_19_cast_uint16_to_int32_dtype_0 = const()[name = string("gather_19_cast_uint16_to_int32_dtype_0"), val = string("int32")];
            int32 gather_20_axis_0 = const()[name = string("gather_20_axis_0"), val = int32(0)];
            int32 gather_20_batch_dims_0 = const()[name = string("gather_20_batch_dims_0"), val = int32(0)];
            bool gather_20_validate_indices_0 = const()[name = string("gather_20_validate_indices_0"), val = bool(false)];
            uint16 gather_20_indices_0_to_uint16 = const()[name = string("gather_20_indices_0_to_uint16"), val = uint16(1)];
            uint16 gather_20_cast_uint16 = gather(axis = gather_20_axis_0, batch_dims = gather_20_batch_dims_0, indices = gather_20_indices_0_to_uint16, validate_indices = gather_20_validate_indices_0, x = var_263_shape_cast_fp16_to_uint16)[name = string("gather_20_cast_uint16")];
            string gather_20_cast_uint16_to_int32_dtype_0 = const()[name = string("gather_20_cast_uint16_to_int32_dtype_0"), val = string("int32")];
            int32 concat_10_axis_0 = const()[name = string("concat_10_axis_0"), val = int32(0)];
            bool concat_10_interleave_0 = const()[name = string("concat_10_interleave_0"), val = bool(false)];
            int32 gather_20_cast_uint16_to_int32 = cast(dtype = gather_20_cast_uint16_to_int32_dtype_0, x = gather_20_cast_uint16)[name = string("cast_82")];
            int32 gather_19_cast_uint16_to_int32 = cast(dtype = gather_19_cast_uint16_to_int32_dtype_0, x = gather_19_cast_uint16)[name = string("cast_83")];
            tensor<int32, [4]> concat_10 = concat(axis = concat_10_axis_0, interleave = concat_10_interleave_0, values = (gather_19_cast_uint16_to_int32, gather_20_cast_uint16_to_int32, var_23, var_22))[name = string("concat_10")];
            tensor<fp16, [?, ?, 12, 32]> x_31_cast_fp16 = reshape(shape = concat_10, x = linear_14_cast_fp16)[name = string("x_31_cast_fp16")];
            tensor<int32, [4]> var_267 = const()[name = string("op_267"), val = tensor<int32, [4]>([0, 2, 1, 3])];
            tensor<int32, [3]> var_269_shape_cast_fp16 = shape(x = linear_12_cast_fp16)[name = string("op_269_shape_cast_fp16")];
            int32 gather_21_axis_0 = const()[name = string("gather_21_axis_0"), val = int32(0)];
            int32 gather_21_batch_dims_0 = const()[name = string("gather_21_batch_dims_0"), val = int32(0)];
            bool gather_21_validate_indices_0 = const()[name = string("gather_21_validate_indices_0"), val = bool(false)];
            string var_269_shape_cast_fp16_to_uint16_dtype_0 = const()[name = string("op_269_shape_cast_fp16_to_uint16_dtype_0"), val = string("uint16")];
            uint16 gather_21_indices_0_to_uint16 = const()[name = string("gather_21_indices_0_to_uint16"), val = uint16(0)];
            tensor<uint16, [3]> var_269_shape_cast_fp16_to_uint16 = cast(dtype = var_269_shape_cast_fp16_to_uint16_dtype_0, x = var_269_shape_cast_fp16)[name = string("cast_81")];
            uint16 gather_21_cast_uint16 = gather(axis = gather_21_axis_0, batch_dims = gather_21_batch_dims_0, indices = gather_21_indices_0_to_uint16, validate_indices = gather_21_validate_indices_0, x = var_269_shape_cast_fp16_to_uint16)[name = string("gather_21_cast_uint16")];
            string gather_21_cast_uint16_to_int32_dtype_0 = const()[name = string("gather_21_cast_uint16_to_int32_dtype_0"), val = string("int32")];
            int32 gather_22_axis_0 = const()[name = string("gather_22_axis_0"), val = int32(0)];
            int32 gather_22_batch_dims_0 = const()[name = string("gather_22_batch_dims_0"), val = int32(0)];
            bool gather_22_validate_indices_0 = const()[name = string("gather_22_validate_indices_0"), val = bool(false)];
            uint16 gather_22_indices_0_to_uint16 = const()[name = string("gather_22_indices_0_to_uint16"), val = uint16(1)];
            uint16 gather_22_cast_uint16 = gather(axis = gather_22_axis_0, batch_dims = gather_22_batch_dims_0, indices = gather_22_indices_0_to_uint16, validate_indices = gather_22_validate_indices_0, x = var_269_shape_cast_fp16_to_uint16)[name = string("gather_22_cast_uint16")];
            string gather_22_cast_uint16_to_int32_dtype_0 = const()[name = string("gather_22_cast_uint16_to_int32_dtype_0"), val = string("int32")];
            int32 concat_11_axis_0 = const()[name = string("concat_11_axis_0"), val = int32(0)];
            bool concat_11_interleave_0 = const()[name = string("concat_11_interleave_0"), val = bool(false)];
            int32 gather_22_cast_uint16_to_int32 = cast(dtype = gather_22_cast_uint16_to_int32_dtype_0, x = gather_22_cast_uint16)[name = string("cast_79")];
            int32 gather_21_cast_uint16_to_int32 = cast(dtype = gather_21_cast_uint16_to_int32_dtype_0, x = gather_21_cast_uint16)[name = string("cast_80")];
            tensor<int32, [4]> concat_11 = concat(axis = concat_11_axis_0, interleave = concat_11_interleave_0, values = (gather_21_cast_uint16_to_int32, gather_22_cast_uint16_to_int32, var_23, var_22))[name = string("concat_11")];
            tensor<fp16, [?, ?, 12, 32]> x_35_cast_fp16 = reshape(shape = concat_11, x = linear_12_cast_fp16)[name = string("x_35_cast_fp16")];
            bool attention_scores_9_transpose_x_0 = const()[name = string("attention_scores_9_transpose_x_0"), val = bool(false)];
            bool attention_scores_9_transpose_y_0 = const()[name = string("attention_scores_9_transpose_y_0"), val = bool(false)];
            tensor<int32, [4]> transpose_22_perm_0 = const()[name = string("transpose_22_perm_0"), val = tensor<int32, [4]>([0, 2, -3, -1])];
            tensor<int32, [4]> transpose_23_perm_0 = const()[name = string("transpose_23_perm_0"), val = tensor<int32, [4]>([0, 2, -1, -3])];
            tensor<fp16, [?, 12, 32, ?]> transpose_23 = transpose(perm = transpose_23_perm_0, x = x_27_cast_fp16)[name = string("transpose_43")];
            tensor<fp16, [?, 12, ?, 32]> transpose_22 = transpose(perm = transpose_22_perm_0, x = x_35_cast_fp16)[name = string("transpose_44")];
            tensor<fp16, [?, 12, ?, ?]> attention_scores_9_cast_fp16 = matmul(transpose_x = attention_scores_9_transpose_x_0, transpose_y = attention_scores_9_transpose_y_0, x = transpose_22, y = transpose_23)[name = string("attention_scores_9_cast_fp16")];
            fp16 _inversed_attention_scores_11_y_0_to_fp16 = const()[name = string("_inversed_attention_scores_11_y_0_to_fp16"), val = fp16(0x1.6ap-3)];
            tensor<fp16, [?, 12, ?, ?]> _inversed_attention_scores_11_cast_fp16 = mul(x = attention_scores_9_cast_fp16, y = _inversed_attention_scores_11_y_0_to_fp16)[name = string("_inversed_attention_scores_11_cast_fp16")];
            tensor<fp16, [?, 12, ?, ?]> input_55_cast_fp16 = add(x = _inversed_attention_scores_11_cast_fp16, y = attention_mask_cast_fp16)[name = string("input_55_cast_fp16")];
            tensor<fp16, [?, 12, ?, ?]> input_57_cast_fp16 = softmax(axis = var_24, x = input_55_cast_fp16)[name = string("input_57_cast_fp16")];
            bool context_layer_9_transpose_x_0 = const()[name = string("context_layer_9_transpose_x_0"), val = bool(false)];
            bool context_layer_9_transpose_y_0 = const()[name = string("context_layer_9_transpose_y_0"), val = bool(false)];
            tensor<fp16, [?, 12, ?, 32]> value_layer_5_cast_fp16 = transpose(perm = var_267, x = x_31_cast_fp16)[name = string("transpose_45")];
            tensor<fp16, [?, 12, ?, 32]> context_layer_9_cast_fp16 = matmul(transpose_x = context_layer_9_transpose_x_0, transpose_y = context_layer_9_transpose_y_0, x = input_57_cast_fp16, y = value_layer_5_cast_fp16)[name = string("context_layer_9_cast_fp16")];
            tensor<int32, [4]> var_283 = const()[name = string("op_283"), val = tensor<int32, [4]>([0, 2, 1, 3])];
            tensor<fp16, [?, ?, 12, 32]> var_284_cast_fp16 = transpose(perm = var_283, x = context_layer_9_cast_fp16)[name = string("transpose_42")];
            tensor<int32, [4]> var_286_shape_cast_fp16 = shape(x = var_284_cast_fp16)[name = string("op_286_shape_cast_fp16")];
            int32 gather_23_axis_0 = const()[name = string("gather_23_axis_0"), val = int32(0)];
            int32 gather_23_batch_dims_0 = const()[name = string("gather_23_batch_dims_0"), val = int32(0)];
            bool gather_23_validate_indices_0 = const()[name = string("gather_23_validate_indices_0"), val = bool(false)];
            string var_286_shape_cast_fp16_to_uint16_dtype_0 = const()[name = string("op_286_shape_cast_fp16_to_uint16_dtype_0"), val = string("uint16")];
            uint16 gather_23_indices_0_to_uint16 = const()[name = string("gather_23_indices_0_to_uint16"), val = uint16(0)];
            tensor<uint16, [4]> var_286_shape_cast_fp16_to_uint16 = cast(dtype = var_286_shape_cast_fp16_to_uint16_dtype_0, x = var_286_shape_cast_fp16)[name = string("cast_78")];
            uint16 gather_23_cast_uint16 = gather(axis = gather_23_axis_0, batch_dims = gather_23_batch_dims_0, indices = gather_23_indices_0_to_uint16, validate_indices = gather_23_validate_indices_0, x = var_286_shape_cast_fp16_to_uint16)[name = string("gather_23_cast_uint16")];
            string gather_23_cast_uint16_to_int32_dtype_0 = const()[name = string("gather_23_cast_uint16_to_int32_dtype_0"), val = string("int32")];
            int32 gather_24_axis_0 = const()[name = string("gather_24_axis_0"), val = int32(0)];
            int32 gather_24_batch_dims_0 = const()[name = string("gather_24_batch_dims_0"), val = int32(0)];
            bool gather_24_validate_indices_0 = const()[name = string("gather_24_validate_indices_0"), val = bool(false)];
            uint16 gather_24_indices_0_to_uint16 = const()[name = string("gather_24_indices_0_to_uint16"), val = uint16(1)];
            uint16 gather_24_cast_uint16 = gather(axis = gather_24_axis_0, batch_dims = gather_24_batch_dims_0, indices = gather_24_indices_0_to_uint16, validate_indices = gather_24_validate_indices_0, x = var_286_shape_cast_fp16_to_uint16)[name = string("gather_24_cast_uint16")];
            string gather_24_cast_uint16_to_int32_dtype_0 = const()[name = string("gather_24_cast_uint16_to_int32_dtype_0"), val = string("int32")];
            int32 concat_12_axis_0 = const()[name = string("concat_12_axis_0"), val = int32(0)];
            bool concat_12_interleave_0 = const()[name = string("concat_12_interleave_0"), val = bool(false)];
            int32 gather_24_cast_uint16_to_int32 = cast(dtype = gather_24_cast_uint16_to_int32_dtype_0, x = gather_24_cast_uint16)[name = string("cast_76")];
            int32 gather_23_cast_uint16_to_int32 = cast(dtype = gather_23_cast_uint16_to_int32_dtype_0, x = gather_23_cast_uint16)[name = string("cast_77")];
            tensor<int32, [3]> concat_12 = concat(axis = concat_12_axis_0, interleave = concat_12_interleave_0, values = (gather_23_cast_uint16_to_int32, gather_24_cast_uint16_to_int32, var_27))[name = string("concat_12")];
            tensor<fp16, [?, ?, 384]> input_59_cast_fp16 = reshape(shape = concat_12, x = var_284_cast_fp16)[name = string("input_59_cast_fp16")];
            tensor<fp16, [384, 384]> model_encoder_layer_2_attention_output_dense_weight_to_fp16 = const()[name = string("model_encoder_layer_2_attention_output_dense_weight_to_fp16"), val = tensor<fp16, [384, 384]>(BLOBFILE(path = string("@model_path/weights/weight.bin"), offset = uint64(31827008)))];
            tensor<fp16, [384]> model_encoder_layer_2_attention_output_dense_bias_to_fp16 = const()[name = string("model_encoder_layer_2_attention_output_dense_bias_to_fp16"), val = tensor<fp16, [384]>(BLOBFILE(path = string("@model_path/weights/weight.bin"), offset = uint64(32121984)))];
            tensor<fp16, [?, ?, 384]> linear_15_cast_fp16 = linear(bias = model_encoder_layer_2_attention_output_dense_bias_to_fp16, weight = model_encoder_layer_2_attention_output_dense_weight_to_fp16, x = input_59_cast_fp16)[name = string("linear_15_cast_fp16")];
            tensor<fp16, [?, ?, 384]> input_63_cast_fp16 = add(x = linear_15_cast_fp16, y = input_53_cast_fp16)[name = string("input_63_cast_fp16")];
            tensor<int32, [1]> input_65_axes_0 = const()[name = string("input_65_axes_0"), val = tensor<int32, [1]>([-1])];
            tensor<fp16, [384]> model_encoder_layer_2_attention_output_LayerNorm_weight_to_fp16 = const()[name = string("model_encoder_layer_2_attention_output_LayerNorm_weight_to_fp16"), val = tensor<fp16, [384]>(BLOBFILE(path = string("@model_path/weights/weight.bin"), offset = uint64(32122816)))];
            tensor<fp16, [384]> model_encoder_layer_2_attention_output_LayerNorm_bias_to_fp16 = const()[name = string("model_encoder_layer_2_attention_output_LayerNorm_bias_to_fp16"), val = tensor<fp16, [384]>(BLOBFILE(path = string("@model_path/weights/weight.bin"), offset = uint64(32123648)))];
            tensor<fp16, [?, ?, 384]> input_65_cast_fp16 = layer_norm(axes = input_65_axes_0, beta = model_encoder_layer_2_attention_output_LayerNorm_bias_to_fp16, epsilon = var_26_to_fp16, gamma = model_encoder_layer_2_attention_output_LayerNorm_weight_to_fp16, x = input_63_cast_fp16)[name = string("input_65_cast_fp16")];
            tensor<fp16, [1536, 384]> model_encoder_layer_2_intermediate_dense_weight_to_fp16 = const()[name = string("model_encoder_layer_2_intermediate_dense_weight_to_fp16"), val = tensor<fp16, [1536, 384]>(BLOBFILE(path = string("@model_path/weights/weight.bin"), offset = uint64(32124480)))];
            tensor<fp16, [1536]> model_encoder_layer_2_intermediate_dense_bias_to_fp16 = const()[name = string("model_encoder_layer_2_intermediate_dense_bias_to_fp16"), val = tensor<fp16, [1536]>(BLOBFILE(path = string("@model_path/weights/weight.bin"), offset = uint64(33304192)))];
            tensor<fp16, [?, ?, 1536]> linear_16_cast_fp16 = linear(bias = model_encoder_layer_2_intermediate_dense_bias_to_fp16, weight = model_encoder_layer_2_intermediate_dense_weight_to_fp16, x = input_65_cast_fp16)[name = string("linear_16_cast_fp16")];
            string input_69_mode_0 = const()[name = string("input_69_mode_0"), val = string("EXACT")];
            tensor<fp16, [?, ?, 1536]> input_69_cast_fp16 = gelu(mode = input_69_mode_0, x = linear_16_cast_fp16)[name = string("input_69_cast_fp16")];
            tensor<fp16, [384, 1536]> model_encoder_layer_2_output_dense_weight_to_fp16 = const()[name = string("model_encoder_layer_2_output_dense_weight_to_fp16"), val = tensor<fp16, [384, 1536]>(BLOBFILE(path = string("@model_path/weights/weight.bin"), offset = uint64(33307328)))];
            tensor<fp16, [384]> model_encoder_layer_2_output_dense_bias_to_fp16 = const()[name = string("model_encoder_layer_2_output_dense_bias_to_fp16"), val = tensor<fp16, [384]>(BLOBFILE(path = string("@model_path/weights/weight.bin"), offset = uint64(34487040)))];
            tensor<fp16, [?, ?, 384]> linear_17_cast_fp16 = linear(bias = model_encoder_layer_2_output_dense_bias_to_fp16, weight = model_encoder_layer_2_output_dense_weight_to_fp16, x = input_69_cast_fp16)[name = string("linear_17_cast_fp16")];
            tensor<fp16, [?, ?, 384]> input_73_cast_fp16 = add(x = linear_17_cast_fp16, y = input_65_cast_fp16)[name = string("input_73_cast_fp16")];
            tensor<int32, [1]> input_75_axes_0 = const()[name = string("input_75_axes_0"), val = tensor<int32, [1]>([-1])];
            tensor<fp16, [384]> model_encoder_layer_2_output_LayerNorm_weight_to_fp16 = const()[name = string("model_encoder_layer_2_output_LayerNorm_weight_to_fp16"), val = tensor<fp16, [384]>(BLOBFILE(path = string("@model_path/weights/weight.bin"), offset = uint64(34487872)))];
            tensor<fp16, [384]> model_encoder_layer_2_output_LayerNorm_bias_to_fp16 = const()[name = string("model_encoder_layer_2_output_LayerNorm_bias_to_fp16"), val = tensor<fp16, [384]>(BLOBFILE(path = string("@model_path/weights/weight.bin"), offset = uint64(34488704)))];
            tensor<fp16, [?, ?, 384]> input_75_cast_fp16 = layer_norm(axes = input_75_axes_0, beta = model_encoder_layer_2_output_LayerNorm_bias_to_fp16, epsilon = var_26_to_fp16, gamma = model_encoder_layer_2_output_LayerNorm_weight_to_fp16, x = input_73_cast_fp16)[name = string("input_75_cast_fp16")];
            tensor<fp16, [384, 384]> model_encoder_layer_3_attention_self_query_weight_to_fp16 = const()[name = string("model_encoder_layer_3_attention_self_query_weight_to_fp16"), val = tensor<fp16, [384, 384]>(BLOBFILE(path = string("@model_path/weights/weight.bin"), offset = uint64(34489536)))];
            tensor<fp16, [384]> model_encoder_layer_3_attention_self_query_bias_to_fp16 = const()[name = string("model_encoder_layer_3_attention_self_query_bias_to_fp16"), val = tensor<fp16, [384]>(BLOBFILE(path = string("@model_path/weights/weight.bin"), offset = uint64(34784512)))];
            tensor<fp16, [?, ?, 384]> linear_18_cast_fp16 = linear(bias = model_encoder_layer_3_attention_self_query_bias_to_fp16, weight = model_encoder_layer_3_attention_self_query_weight_to_fp16, x = input_75_cast_fp16)[name = string("linear_18_cast_fp16")];
            tensor<fp16, [384, 384]> model_encoder_layer_3_attention_self_key_weight_to_fp16 = const()[name = string("model_encoder_layer_3_attention_self_key_weight_to_fp16"), val = tensor<fp16, [384, 384]>(BLOBFILE(path = string("@model_path/weights/weight.bin"), offset = uint64(34785344)))];
            tensor<fp16, [384]> model_encoder_layer_3_attention_self_key_bias_to_fp16 = const()[name = string("model_encoder_layer_3_attention_self_key_bias_to_fp16"), val = tensor<fp16, [384]>(BLOBFILE(path = string("@model_path/weights/weight.bin"), offset = uint64(35080320)))];
            tensor<fp16, [?, ?, 384]> linear_19_cast_fp16 = linear(bias = model_encoder_layer_3_attention_self_key_bias_to_fp16, weight = model_encoder_layer_3_attention_self_key_weight_to_fp16, x = input_75_cast_fp16)[name = string("linear_19_cast_fp16")];
            tensor<int32, [3]> var_331_shape_cast_fp16 = shape(x = linear_19_cast_fp16)[name = string("op_331_shape_cast_fp16")];
            int32 gather_25_axis_0 = const()[name = string("gather_25_axis_0"), val = int32(0)];
            int32 gather_25_batch_dims_0 = const()[name = string("gather_25_batch_dims_0"), val = int32(0)];
            bool gather_25_validate_indices_0 = const()[name = string("gather_25_validate_indices_0"), val = bool(false)];
            string var_331_shape_cast_fp16_to_uint16_dtype_0 = const()[name = string("op_331_shape_cast_fp16_to_uint16_dtype_0"), val = string("uint16")];
            uint16 gather_25_indices_0_to_uint16 = const()[name = string("gather_25_indices_0_to_uint16"), val = uint16(0)];
            tensor<uint16, [3]> var_331_shape_cast_fp16_to_uint16 = cast(dtype = var_331_shape_cast_fp16_to_uint16_dtype_0, x = var_331_shape_cast_fp16)[name = string("cast_75")];
            uint16 gather_25_cast_uint16 = gather(axis = gather_25_axis_0, batch_dims = gather_25_batch_dims_0, indices = gather_25_indices_0_to_uint16, validate_indices = gather_25_validate_indices_0, x = var_331_shape_cast_fp16_to_uint16)[name = string("gather_25_cast_uint16")];
            string gather_25_cast_uint16_to_int32_dtype_0 = const()[name = string("gather_25_cast_uint16_to_int32_dtype_0"), val = string("int32")];
            int32 gather_26_axis_0 = const()[name = string("gather_26_axis_0"), val = int32(0)];
            int32 gather_26_batch_dims_0 = const()[name = string("gather_26_batch_dims_0"), val = int32(0)];
            bool gather_26_validate_indices_0 = const()[name = string("gather_26_validate_indices_0"), val = bool(false)];
            uint16 gather_26_indices_0_to_uint16 = const()[name = string("gather_26_indices_0_to_uint16"), val = uint16(1)];
            uint16 gather_26_cast_uint16 = gather(axis = gather_26_axis_0, batch_dims = gather_26_batch_dims_0, indices = gather_26_indices_0_to_uint16, validate_indices = gather_26_validate_indices_0, x = var_331_shape_cast_fp16_to_uint16)[name = string("gather_26_cast_uint16")];
            string gather_26_cast_uint16_to_int32_dtype_0 = const()[name = string("gather_26_cast_uint16_to_int32_dtype_0"), val = string("int32")];
            int32 concat_13_axis_0 = const()[name = string("concat_13_axis_0"), val = int32(0)];
            bool concat_13_interleave_0 = const()[name = string("concat_13_interleave_0"), val = bool(false)];
            int32 gather_26_cast_uint16_to_int32 = cast(dtype = gather_26_cast_uint16_to_int32_dtype_0, x = gather_26_cast_uint16)[name = string("cast_73")];
            int32 gather_25_cast_uint16_to_int32 = cast(dtype = gather_25_cast_uint16_to_int32_dtype_0, x = gather_25_cast_uint16)[name = string("cast_74")];
            tensor<int32, [4]> concat_13 = concat(axis = concat_13_axis_0, interleave = concat_13_interleave_0, values = (gather_25_cast_uint16_to_int32, gather_26_cast_uint16_to_int32, var_23, var_22))[name = string("concat_13")];
            tensor<fp16, [?, ?, 12, 32]> x_39_cast_fp16 = reshape(shape = concat_13, x = linear_19_cast_fp16)[name = string("x_39_cast_fp16")];
            tensor<fp16, [384, 384]> model_encoder_layer_3_attention_self_value_weight_to_fp16 = const()[name = string("model_encoder_layer_3_attention_self_value_weight_to_fp16"), val = tensor<fp16, [384, 384]>(BLOBFILE(path = string("@model_path/weights/weight.bin"), offset = uint64(35081152)))];
            tensor<fp16, [384]> model_encoder_layer_3_attention_self_value_bias_to_fp16 = const()[name = string("model_encoder_layer_3_attention_self_value_bias_to_fp16"), val = tensor<fp16, [384]>(BLOBFILE(path = string("@model_path/weights/weight.bin"), offset = uint64(35376128)))];
            tensor<fp16, [?, ?, 384]> linear_20_cast_fp16 = linear(bias = model_encoder_layer_3_attention_self_value_bias_to_fp16, weight = model_encoder_layer_3_attention_self_value_weight_to_fp16, x = input_75_cast_fp16)[name = string("linear_20_cast_fp16")];
            tensor<int32, [3]> var_340_shape_cast_fp16 = shape(x = linear_20_cast_fp16)[name = string("op_340_shape_cast_fp16")];
            int32 gather_27_axis_0 = const()[name = string("gather_27_axis_0"), val = int32(0)];
            int32 gather_27_batch_dims_0 = const()[name = string("gather_27_batch_dims_0"), val = int32(0)];
            bool gather_27_validate_indices_0 = const()[name = string("gather_27_validate_indices_0"), val = bool(false)];
            string var_340_shape_cast_fp16_to_uint16_dtype_0 = const()[name = string("op_340_shape_cast_fp16_to_uint16_dtype_0"), val = string("uint16")];
            uint16 gather_27_indices_0_to_uint16 = const()[name = string("gather_27_indices_0_to_uint16"), val = uint16(0)];
            tensor<uint16, [3]> var_340_shape_cast_fp16_to_uint16 = cast(dtype = var_340_shape_cast_fp16_to_uint16_dtype_0, x = var_340_shape_cast_fp16)[name = string("cast_72")];
            uint16 gather_27_cast_uint16 = gather(axis = gather_27_axis_0, batch_dims = gather_27_batch_dims_0, indices = gather_27_indices_0_to_uint16, validate_indices = gather_27_validate_indices_0, x = var_340_shape_cast_fp16_to_uint16)[name = string("gather_27_cast_uint16")];
            string gather_27_cast_uint16_to_int32_dtype_0 = const()[name = string("gather_27_cast_uint16_to_int32_dtype_0"), val = string("int32")];
            int32 gather_28_axis_0 = const()[name = string("gather_28_axis_0"), val = int32(0)];
            int32 gather_28_batch_dims_0 = const()[name = string("gather_28_batch_dims_0"), val = int32(0)];
            bool gather_28_validate_indices_0 = const()[name = string("gather_28_validate_indices_0"), val = bool(false)];
            uint16 gather_28_indices_0_to_uint16 = const()[name = string("gather_28_indices_0_to_uint16"), val = uint16(1)];
            uint16 gather_28_cast_uint16 = gather(axis = gather_28_axis_0, batch_dims = gather_28_batch_dims_0, indices = gather_28_indices_0_to_uint16, validate_indices = gather_28_validate_indices_0, x = var_340_shape_cast_fp16_to_uint16)[name = string("gather_28_cast_uint16")];
            string gather_28_cast_uint16_to_int32_dtype_0 = const()[name = string("gather_28_cast_uint16_to_int32_dtype_0"), val = string("int32")];
            int32 concat_14_axis_0 = const()[name = string("concat_14_axis_0"), val = int32(0)];
            bool concat_14_interleave_0 = const()[name = string("concat_14_interleave_0"), val = bool(false)];
            int32 gather_28_cast_uint16_to_int32 = cast(dtype = gather_28_cast_uint16_to_int32_dtype_0, x = gather_28_cast_uint16)[name = string("cast_70")];
            int32 gather_27_cast_uint16_to_int32 = cast(dtype = gather_27_cast_uint16_to_int32_dtype_0, x = gather_27_cast_uint16)[name = string("cast_71")];
            tensor<int32, [4]> concat_14 = concat(axis = concat_14_axis_0, interleave = concat_14_interleave_0, values = (gather_27_cast_uint16_to_int32, gather_28_cast_uint16_to_int32, var_23, var_22))[name = string("concat_14")];
            tensor<fp16, [?, ?, 12, 32]> x_43_cast_fp16 = reshape(shape = concat_14, x = linear_20_cast_fp16)[name = string("x_43_cast_fp16")];
            tensor<int32, [4]> var_344 = const()[name = string("op_344"), val = tensor<int32, [4]>([0, 2, 1, 3])];
            tensor<int32, [3]> var_346_shape_cast_fp16 = shape(x = linear_18_cast_fp16)[name = string("op_346_shape_cast_fp16")];
            int32 gather_29_axis_0 = const()[name = string("gather_29_axis_0"), val = int32(0)];
            int32 gather_29_batch_dims_0 = const()[name = string("gather_29_batch_dims_0"), val = int32(0)];
            bool gather_29_validate_indices_0 = const()[name = string("gather_29_validate_indices_0"), val = bool(false)];
            string var_346_shape_cast_fp16_to_uint16_dtype_0 = const()[name = string("op_346_shape_cast_fp16_to_uint16_dtype_0"), val = string("uint16")];
            uint16 gather_29_indices_0_to_uint16 = const()[name = string("gather_29_indices_0_to_uint16"), val = uint16(0)];
            tensor<uint16, [3]> var_346_shape_cast_fp16_to_uint16 = cast(dtype = var_346_shape_cast_fp16_to_uint16_dtype_0, x = var_346_shape_cast_fp16)[name = string("cast_69")];
            uint16 gather_29_cast_uint16 = gather(axis = gather_29_axis_0, batch_dims = gather_29_batch_dims_0, indices = gather_29_indices_0_to_uint16, validate_indices = gather_29_validate_indices_0, x = var_346_shape_cast_fp16_to_uint16)[name = string("gather_29_cast_uint16")];
            string gather_29_cast_uint16_to_int32_dtype_0 = const()[name = string("gather_29_cast_uint16_to_int32_dtype_0"), val = string("int32")];
            int32 gather_30_axis_0 = const()[name = string("gather_30_axis_0"), val = int32(0)];
            int32 gather_30_batch_dims_0 = const()[name = string("gather_30_batch_dims_0"), val = int32(0)];
            bool gather_30_validate_indices_0 = const()[name = string("gather_30_validate_indices_0"), val = bool(false)];
            uint16 gather_30_indices_0_to_uint16 = const()[name = string("gather_30_indices_0_to_uint16"), val = uint16(1)];
            uint16 gather_30_cast_uint16 = gather(axis = gather_30_axis_0, batch_dims = gather_30_batch_dims_0, indices = gather_30_indices_0_to_uint16, validate_indices = gather_30_validate_indices_0, x = var_346_shape_cast_fp16_to_uint16)[name = string("gather_30_cast_uint16")];
            string gather_30_cast_uint16_to_int32_dtype_0 = const()[name = string("gather_30_cast_uint16_to_int32_dtype_0"), val = string("int32")];
            int32 concat_15_axis_0 = const()[name = string("concat_15_axis_0"), val = int32(0)];
            bool concat_15_interleave_0 = const()[name = string("concat_15_interleave_0"), val = bool(false)];
            int32 gather_30_cast_uint16_to_int32 = cast(dtype = gather_30_cast_uint16_to_int32_dtype_0, x = gather_30_cast_uint16)[name = string("cast_67")];
            int32 gather_29_cast_uint16_to_int32 = cast(dtype = gather_29_cast_uint16_to_int32_dtype_0, x = gather_29_cast_uint16)[name = string("cast_68")];
            tensor<int32, [4]> concat_15 = concat(axis = concat_15_axis_0, interleave = concat_15_interleave_0, values = (gather_29_cast_uint16_to_int32, gather_30_cast_uint16_to_int32, var_23, var_22))[name = string("concat_15")];
            tensor<fp16, [?, ?, 12, 32]> x_47_cast_fp16 = reshape(shape = concat_15, x = linear_18_cast_fp16)[name = string("x_47_cast_fp16")];
            bool attention_scores_13_transpose_x_0 = const()[name = string("attention_scores_13_transpose_x_0"), val = bool(false)];
            bool attention_scores_13_transpose_y_0 = const()[name = string("attention_scores_13_transpose_y_0"), val = bool(false)];
            tensor<int32, [4]> transpose_24_perm_0 = const()[name = string("transpose_24_perm_0"), val = tensor<int32, [4]>([0, 2, -3, -1])];
            tensor<int32, [4]> transpose_25_perm_0 = const()[name = string("transpose_25_perm_0"), val = tensor<int32, [4]>([0, 2, -1, -3])];
            tensor<fp16, [?, 12, 32, ?]> transpose_25 = transpose(perm = transpose_25_perm_0, x = x_39_cast_fp16)[name = string("transpose_39")];
            tensor<fp16, [?, 12, ?, 32]> transpose_24 = transpose(perm = transpose_24_perm_0, x = x_47_cast_fp16)[name = string("transpose_40")];
            tensor<fp16, [?, 12, ?, ?]> attention_scores_13_cast_fp16 = matmul(transpose_x = attention_scores_13_transpose_x_0, transpose_y = attention_scores_13_transpose_y_0, x = transpose_24, y = transpose_25)[name = string("attention_scores_13_cast_fp16")];
            fp16 _inversed_attention_scores_15_y_0_to_fp16 = const()[name = string("_inversed_attention_scores_15_y_0_to_fp16"), val = fp16(0x1.6ap-3)];
            tensor<fp16, [?, 12, ?, ?]> _inversed_attention_scores_15_cast_fp16 = mul(x = attention_scores_13_cast_fp16, y = _inversed_attention_scores_15_y_0_to_fp16)[name = string("_inversed_attention_scores_15_cast_fp16")];
            tensor<fp16, [?, 12, ?, ?]> input_77_cast_fp16 = add(x = _inversed_attention_scores_15_cast_fp16, y = attention_mask_cast_fp16)[name = string("input_77_cast_fp16")];
            tensor<fp16, [?, 12, ?, ?]> input_79_cast_fp16 = softmax(axis = var_24, x = input_77_cast_fp16)[name = string("input_79_cast_fp16")];
            bool context_layer_13_transpose_x_0 = const()[name = string("context_layer_13_transpose_x_0"), val = bool(false)];
            bool context_layer_13_transpose_y_0 = const()[name = string("context_layer_13_transpose_y_0"), val = bool(false)];
            tensor<fp16, [?, 12, ?, 32]> value_layer_7_cast_fp16 = transpose(perm = var_344, x = x_43_cast_fp16)[name = string("transpose_41")];
            tensor<fp16, [?, 12, ?, 32]> context_layer_13_cast_fp16 = matmul(transpose_x = context_layer_13_transpose_x_0, transpose_y = context_layer_13_transpose_y_0, x = input_79_cast_fp16, y = value_layer_7_cast_fp16)[name = string("context_layer_13_cast_fp16")];
            tensor<int32, [4]> var_360 = const()[name = string("op_360"), val = tensor<int32, [4]>([0, 2, 1, 3])];
            tensor<fp16, [?, ?, 12, 32]> var_361_cast_fp16 = transpose(perm = var_360, x = context_layer_13_cast_fp16)[name = string("transpose_38")];
            tensor<int32, [4]> var_363_shape_cast_fp16 = shape(x = var_361_cast_fp16)[name = string("op_363_shape_cast_fp16")];
            int32 gather_31_axis_0 = const()[name = string("gather_31_axis_0"), val = int32(0)];
            int32 gather_31_batch_dims_0 = const()[name = string("gather_31_batch_dims_0"), val = int32(0)];
            bool gather_31_validate_indices_0 = const()[name = string("gather_31_validate_indices_0"), val = bool(false)];
            string var_363_shape_cast_fp16_to_uint16_dtype_0 = const()[name = string("op_363_shape_cast_fp16_to_uint16_dtype_0"), val = string("uint16")];
            uint16 gather_31_indices_0_to_uint16 = const()[name = string("gather_31_indices_0_to_uint16"), val = uint16(0)];
            tensor<uint16, [4]> var_363_shape_cast_fp16_to_uint16 = cast(dtype = var_363_shape_cast_fp16_to_uint16_dtype_0, x = var_363_shape_cast_fp16)[name = string("cast_66")];
            uint16 gather_31_cast_uint16 = gather(axis = gather_31_axis_0, batch_dims = gather_31_batch_dims_0, indices = gather_31_indices_0_to_uint16, validate_indices = gather_31_validate_indices_0, x = var_363_shape_cast_fp16_to_uint16)[name = string("gather_31_cast_uint16")];
            string gather_31_cast_uint16_to_int32_dtype_0 = const()[name = string("gather_31_cast_uint16_to_int32_dtype_0"), val = string("int32")];
            int32 gather_32_axis_0 = const()[name = string("gather_32_axis_0"), val = int32(0)];
            int32 gather_32_batch_dims_0 = const()[name = string("gather_32_batch_dims_0"), val = int32(0)];
            bool gather_32_validate_indices_0 = const()[name = string("gather_32_validate_indices_0"), val = bool(false)];
            uint16 gather_32_indices_0_to_uint16 = const()[name = string("gather_32_indices_0_to_uint16"), val = uint16(1)];
            uint16 gather_32_cast_uint16 = gather(axis = gather_32_axis_0, batch_dims = gather_32_batch_dims_0, indices = gather_32_indices_0_to_uint16, validate_indices = gather_32_validate_indices_0, x = var_363_shape_cast_fp16_to_uint16)[name = string("gather_32_cast_uint16")];
            string gather_32_cast_uint16_to_int32_dtype_0 = const()[name = string("gather_32_cast_uint16_to_int32_dtype_0"), val = string("int32")];
            int32 concat_16_axis_0 = const()[name = string("concat_16_axis_0"), val = int32(0)];
            bool concat_16_interleave_0 = const()[name = string("concat_16_interleave_0"), val = bool(false)];
            int32 gather_32_cast_uint16_to_int32 = cast(dtype = gather_32_cast_uint16_to_int32_dtype_0, x = gather_32_cast_uint16)[name = string("cast_64")];
            int32 gather_31_cast_uint16_to_int32 = cast(dtype = gather_31_cast_uint16_to_int32_dtype_0, x = gather_31_cast_uint16)[name = string("cast_65")];
            tensor<int32, [3]> concat_16 = concat(axis = concat_16_axis_0, interleave = concat_16_interleave_0, values = (gather_31_cast_uint16_to_int32, gather_32_cast_uint16_to_int32, var_27))[name = string("concat_16")];
            tensor<fp16, [?, ?, 384]> input_81_cast_fp16 = reshape(shape = concat_16, x = var_361_cast_fp16)[name = string("input_81_cast_fp16")];
            tensor<fp16, [384, 384]> model_encoder_layer_3_attention_output_dense_weight_to_fp16 = const()[name = string("model_encoder_layer_3_attention_output_dense_weight_to_fp16"), val = tensor<fp16, [384, 384]>(BLOBFILE(path = string("@model_path/weights/weight.bin"), offset = uint64(35376960)))];
            tensor<fp16, [384]> model_encoder_layer_3_attention_output_dense_bias_to_fp16 = const()[name = string("model_encoder_layer_3_attention_output_dense_bias_to_fp16"), val = tensor<fp16, [384]>(BLOBFILE(path = string("@model_path/weights/weight.bin"), offset = uint64(35671936)))];
            tensor<fp16, [?, ?, 384]> linear_21_cast_fp16 = linear(bias = model_encoder_layer_3_attention_output_dense_bias_to_fp16, weight = model_encoder_layer_3_attention_output_dense_weight_to_fp16, x = input_81_cast_fp16)[name = string("linear_21_cast_fp16")];
            tensor<fp16, [?, ?, 384]> input_85_cast_fp16 = add(x = linear_21_cast_fp16, y = input_75_cast_fp16)[name = string("input_85_cast_fp16")];
            tensor<int32, [1]> input_87_axes_0 = const()[name = string("input_87_axes_0"), val = tensor<int32, [1]>([-1])];
            tensor<fp16, [384]> model_encoder_layer_3_attention_output_LayerNorm_weight_to_fp16 = const()[name = string("model_encoder_layer_3_attention_output_LayerNorm_weight_to_fp16"), val = tensor<fp16, [384]>(BLOBFILE(path = string("@model_path/weights/weight.bin"), offset = uint64(35672768)))];
            tensor<fp16, [384]> model_encoder_layer_3_attention_output_LayerNorm_bias_to_fp16 = const()[name = string("model_encoder_layer_3_attention_output_LayerNorm_bias_to_fp16"), val = tensor<fp16, [384]>(BLOBFILE(path = string("@model_path/weights/weight.bin"), offset = uint64(35673600)))];
            tensor<fp16, [?, ?, 384]> input_87_cast_fp16 = layer_norm(axes = input_87_axes_0, beta = model_encoder_layer_3_attention_output_LayerNorm_bias_to_fp16, epsilon = var_26_to_fp16, gamma = model_encoder_layer_3_attention_output_LayerNorm_weight_to_fp16, x = input_85_cast_fp16)[name = string("input_87_cast_fp16")];
            tensor<fp16, [1536, 384]> model_encoder_layer_3_intermediate_dense_weight_to_fp16 = const()[name = string("model_encoder_layer_3_intermediate_dense_weight_to_fp16"), val = tensor<fp16, [1536, 384]>(BLOBFILE(path = string("@model_path/weights/weight.bin"), offset = uint64(35674432)))];
            tensor<fp16, [1536]> model_encoder_layer_3_intermediate_dense_bias_to_fp16 = const()[name = string("model_encoder_layer_3_intermediate_dense_bias_to_fp16"), val = tensor<fp16, [1536]>(BLOBFILE(path = string("@model_path/weights/weight.bin"), offset = uint64(36854144)))];
            tensor<fp16, [?, ?, 1536]> linear_22_cast_fp16 = linear(bias = model_encoder_layer_3_intermediate_dense_bias_to_fp16, weight = model_encoder_layer_3_intermediate_dense_weight_to_fp16, x = input_87_cast_fp16)[name = string("linear_22_cast_fp16")];
            string input_91_mode_0 = const()[name = string("input_91_mode_0"), val = string("EXACT")];
            tensor<fp16, [?, ?, 1536]> input_91_cast_fp16 = gelu(mode = input_91_mode_0, x = linear_22_cast_fp16)[name = string("input_91_cast_fp16")];
            tensor<fp16, [384, 1536]> model_encoder_layer_3_output_dense_weight_to_fp16 = const()[name = string("model_encoder_layer_3_output_dense_weight_to_fp16"), val = tensor<fp16, [384, 1536]>(BLOBFILE(path = string("@model_path/weights/weight.bin"), offset = uint64(36857280)))];
            tensor<fp16, [384]> model_encoder_layer_3_output_dense_bias_to_fp16 = const()[name = string("model_encoder_layer_3_output_dense_bias_to_fp16"), val = tensor<fp16, [384]>(BLOBFILE(path = string("@model_path/weights/weight.bin"), offset = uint64(38036992)))];
            tensor<fp16, [?, ?, 384]> linear_23_cast_fp16 = linear(bias = model_encoder_layer_3_output_dense_bias_to_fp16, weight = model_encoder_layer_3_output_dense_weight_to_fp16, x = input_91_cast_fp16)[name = string("linear_23_cast_fp16")];
            tensor<fp16, [?, ?, 384]> input_95_cast_fp16 = add(x = linear_23_cast_fp16, y = input_87_cast_fp16)[name = string("input_95_cast_fp16")];
            tensor<int32, [1]> input_97_axes_0 = const()[name = string("input_97_axes_0"), val = tensor<int32, [1]>([-1])];
            tensor<fp16, [384]> model_encoder_layer_3_output_LayerNorm_weight_to_fp16 = const()[name = string("model_encoder_layer_3_output_LayerNorm_weight_to_fp16"), val = tensor<fp16, [384]>(BLOBFILE(path = string("@model_path/weights/weight.bin"), offset = uint64(38037824)))];
            tensor<fp16, [384]> model_encoder_layer_3_output_LayerNorm_bias_to_fp16 = const()[name = string("model_encoder_layer_3_output_LayerNorm_bias_to_fp16"), val = tensor<fp16, [384]>(BLOBFILE(path = string("@model_path/weights/weight.bin"), offset = uint64(38038656)))];
            tensor<fp16, [?, ?, 384]> input_97_cast_fp16 = layer_norm(axes = input_97_axes_0, beta = model_encoder_layer_3_output_LayerNorm_bias_to_fp16, epsilon = var_26_to_fp16, gamma = model_encoder_layer_3_output_LayerNorm_weight_to_fp16, x = input_95_cast_fp16)[name = string("input_97_cast_fp16")];
            tensor<fp16, [384, 384]> model_encoder_layer_4_attention_self_query_weight_to_fp16 = const()[name = string("model_encoder_layer_4_attention_self_query_weight_to_fp16"), val = tensor<fp16, [384, 384]>(BLOBFILE(path = string("@model_path/weights/weight.bin"), offset = uint64(38039488)))];
            tensor<fp16, [384]> model_encoder_layer_4_attention_self_query_bias_to_fp16 = const()[name = string("model_encoder_layer_4_attention_self_query_bias_to_fp16"), val = tensor<fp16, [384]>(BLOBFILE(path = string("@model_path/weights/weight.bin"), offset = uint64(38334464)))];
            tensor<fp16, [?, ?, 384]> linear_24_cast_fp16 = linear(bias = model_encoder_layer_4_attention_self_query_bias_to_fp16, weight = model_encoder_layer_4_attention_self_query_weight_to_fp16, x = input_97_cast_fp16)[name = string("linear_24_cast_fp16")];
            tensor<fp16, [384, 384]> model_encoder_layer_4_attention_self_key_weight_to_fp16 = const()[name = string("model_encoder_layer_4_attention_self_key_weight_to_fp16"), val = tensor<fp16, [384, 384]>(BLOBFILE(path = string("@model_path/weights/weight.bin"), offset = uint64(38335296)))];
            tensor<fp16, [384]> model_encoder_layer_4_attention_self_key_bias_to_fp16 = const()[name = string("model_encoder_layer_4_attention_self_key_bias_to_fp16"), val = tensor<fp16, [384]>(BLOBFILE(path = string("@model_path/weights/weight.bin"), offset = uint64(38630272)))];
            tensor<fp16, [?, ?, 384]> linear_25_cast_fp16 = linear(bias = model_encoder_layer_4_attention_self_key_bias_to_fp16, weight = model_encoder_layer_4_attention_self_key_weight_to_fp16, x = input_97_cast_fp16)[name = string("linear_25_cast_fp16")];
            tensor<int32, [3]> var_408_shape_cast_fp16 = shape(x = linear_25_cast_fp16)[name = string("op_408_shape_cast_fp16")];
            int32 gather_33_axis_0 = const()[name = string("gather_33_axis_0"), val = int32(0)];
            int32 gather_33_batch_dims_0 = const()[name = string("gather_33_batch_dims_0"), val = int32(0)];
            bool gather_33_validate_indices_0 = const()[name = string("gather_33_validate_indices_0"), val = bool(false)];
            string var_408_shape_cast_fp16_to_uint16_dtype_0 = const()[name = string("op_408_shape_cast_fp16_to_uint16_dtype_0"), val = string("uint16")];
            uint16 gather_33_indices_0_to_uint16 = const()[name = string("gather_33_indices_0_to_uint16"), val = uint16(0)];
            tensor<uint16, [3]> var_408_shape_cast_fp16_to_uint16 = cast(dtype = var_408_shape_cast_fp16_to_uint16_dtype_0, x = var_408_shape_cast_fp16)[name = string("cast_63")];
            uint16 gather_33_cast_uint16 = gather(axis = gather_33_axis_0, batch_dims = gather_33_batch_dims_0, indices = gather_33_indices_0_to_uint16, validate_indices = gather_33_validate_indices_0, x = var_408_shape_cast_fp16_to_uint16)[name = string("gather_33_cast_uint16")];
            string gather_33_cast_uint16_to_int32_dtype_0 = const()[name = string("gather_33_cast_uint16_to_int32_dtype_0"), val = string("int32")];
            int32 gather_34_axis_0 = const()[name = string("gather_34_axis_0"), val = int32(0)];
            int32 gather_34_batch_dims_0 = const()[name = string("gather_34_batch_dims_0"), val = int32(0)];
            bool gather_34_validate_indices_0 = const()[name = string("gather_34_validate_indices_0"), val = bool(false)];
            uint16 gather_34_indices_0_to_uint16 = const()[name = string("gather_34_indices_0_to_uint16"), val = uint16(1)];
            uint16 gather_34_cast_uint16 = gather(axis = gather_34_axis_0, batch_dims = gather_34_batch_dims_0, indices = gather_34_indices_0_to_uint16, validate_indices = gather_34_validate_indices_0, x = var_408_shape_cast_fp16_to_uint16)[name = string("gather_34_cast_uint16")];
            string gather_34_cast_uint16_to_int32_dtype_0 = const()[name = string("gather_34_cast_uint16_to_int32_dtype_0"), val = string("int32")];
            int32 concat_17_axis_0 = const()[name = string("concat_17_axis_0"), val = int32(0)];
            bool concat_17_interleave_0 = const()[name = string("concat_17_interleave_0"), val = bool(false)];
            int32 gather_34_cast_uint16_to_int32 = cast(dtype = gather_34_cast_uint16_to_int32_dtype_0, x = gather_34_cast_uint16)[name = string("cast_61")];
            int32 gather_33_cast_uint16_to_int32 = cast(dtype = gather_33_cast_uint16_to_int32_dtype_0, x = gather_33_cast_uint16)[name = string("cast_62")];
            tensor<int32, [4]> concat_17 = concat(axis = concat_17_axis_0, interleave = concat_17_interleave_0, values = (gather_33_cast_uint16_to_int32, gather_34_cast_uint16_to_int32, var_23, var_22))[name = string("concat_17")];
            tensor<fp16, [?, ?, 12, 32]> x_51_cast_fp16 = reshape(shape = concat_17, x = linear_25_cast_fp16)[name = string("x_51_cast_fp16")];
            tensor<fp16, [384, 384]> model_encoder_layer_4_attention_self_value_weight_to_fp16 = const()[name = string("model_encoder_layer_4_attention_self_value_weight_to_fp16"), val = tensor<fp16, [384, 384]>(BLOBFILE(path = string("@model_path/weights/weight.bin"), offset = uint64(38631104)))];
            tensor<fp16, [384]> model_encoder_layer_4_attention_self_value_bias_to_fp16 = const()[name = string("model_encoder_layer_4_attention_self_value_bias_to_fp16"), val = tensor<fp16, [384]>(BLOBFILE(path = string("@model_path/weights/weight.bin"), offset = uint64(38926080)))];
            tensor<fp16, [?, ?, 384]> linear_26_cast_fp16 = linear(bias = model_encoder_layer_4_attention_self_value_bias_to_fp16, weight = model_encoder_layer_4_attention_self_value_weight_to_fp16, x = input_97_cast_fp16)[name = string("linear_26_cast_fp16")];
            tensor<int32, [3]> var_417_shape_cast_fp16 = shape(x = linear_26_cast_fp16)[name = string("op_417_shape_cast_fp16")];
            int32 gather_35_axis_0 = const()[name = string("gather_35_axis_0"), val = int32(0)];
            int32 gather_35_batch_dims_0 = const()[name = string("gather_35_batch_dims_0"), val = int32(0)];
            bool gather_35_validate_indices_0 = const()[name = string("gather_35_validate_indices_0"), val = bool(false)];
            string var_417_shape_cast_fp16_to_uint16_dtype_0 = const()[name = string("op_417_shape_cast_fp16_to_uint16_dtype_0"), val = string("uint16")];
            uint16 gather_35_indices_0_to_uint16 = const()[name = string("gather_35_indices_0_to_uint16"), val = uint16(0)];
            tensor<uint16, [3]> var_417_shape_cast_fp16_to_uint16 = cast(dtype = var_417_shape_cast_fp16_to_uint16_dtype_0, x = var_417_shape_cast_fp16)[name = string("cast_60")];
            uint16 gather_35_cast_uint16 = gather(axis = gather_35_axis_0, batch_dims = gather_35_batch_dims_0, indices = gather_35_indices_0_to_uint16, validate_indices = gather_35_validate_indices_0, x = var_417_shape_cast_fp16_to_uint16)[name = string("gather_35_cast_uint16")];
            string gather_35_cast_uint16_to_int32_dtype_0 = const()[name = string("gather_35_cast_uint16_to_int32_dtype_0"), val = string("int32")];
            int32 gather_36_axis_0 = const()[name = string("gather_36_axis_0"), val = int32(0)];
            int32 gather_36_batch_dims_0 = const()[name = string("gather_36_batch_dims_0"), val = int32(0)];
            bool gather_36_validate_indices_0 = const()[name = string("gather_36_validate_indices_0"), val = bool(false)];
            uint16 gather_36_indices_0_to_uint16 = const()[name = string("gather_36_indices_0_to_uint16"), val = uint16(1)];
            uint16 gather_36_cast_uint16 = gather(axis = gather_36_axis_0, batch_dims = gather_36_batch_dims_0, indices = gather_36_indices_0_to_uint16, validate_indices = gather_36_validate_indices_0, x = var_417_shape_cast_fp16_to_uint16)[name = string("gather_36_cast_uint16")];
            string gather_36_cast_uint16_to_int32_dtype_0 = const()[name = string("gather_36_cast_uint16_to_int32_dtype_0"), val = string("int32")];
            int32 concat_18_axis_0 = const()[name = string("concat_18_axis_0"), val = int32(0)];
            bool concat_18_interleave_0 = const()[name = string("concat_18_interleave_0"), val = bool(false)];
            int32 gather_36_cast_uint16_to_int32 = cast(dtype = gather_36_cast_uint16_to_int32_dtype_0, x = gather_36_cast_uint16)[name = string("cast_58")];
            int32 gather_35_cast_uint16_to_int32 = cast(dtype = gather_35_cast_uint16_to_int32_dtype_0, x = gather_35_cast_uint16)[name = string("cast_59")];
            tensor<int32, [4]> concat_18 = concat(axis = concat_18_axis_0, interleave = concat_18_interleave_0, values = (gather_35_cast_uint16_to_int32, gather_36_cast_uint16_to_int32, var_23, var_22))[name = string("concat_18")];
            tensor<fp16, [?, ?, 12, 32]> x_55_cast_fp16 = reshape(shape = concat_18, x = linear_26_cast_fp16)[name = string("x_55_cast_fp16")];
            tensor<int32, [4]> var_421 = const()[name = string("op_421"), val = tensor<int32, [4]>([0, 2, 1, 3])];
            tensor<int32, [3]> var_423_shape_cast_fp16 = shape(x = linear_24_cast_fp16)[name = string("op_423_shape_cast_fp16")];
            int32 gather_37_axis_0 = const()[name = string("gather_37_axis_0"), val = int32(0)];
            int32 gather_37_batch_dims_0 = const()[name = string("gather_37_batch_dims_0"), val = int32(0)];
            bool gather_37_validate_indices_0 = const()[name = string("gather_37_validate_indices_0"), val = bool(false)];
            string var_423_shape_cast_fp16_to_uint16_dtype_0 = const()[name = string("op_423_shape_cast_fp16_to_uint16_dtype_0"), val = string("uint16")];
            uint16 gather_37_indices_0_to_uint16 = const()[name = string("gather_37_indices_0_to_uint16"), val = uint16(0)];
            tensor<uint16, [3]> var_423_shape_cast_fp16_to_uint16 = cast(dtype = var_423_shape_cast_fp16_to_uint16_dtype_0, x = var_423_shape_cast_fp16)[name = string("cast_57")];
            uint16 gather_37_cast_uint16 = gather(axis = gather_37_axis_0, batch_dims = gather_37_batch_dims_0, indices = gather_37_indices_0_to_uint16, validate_indices = gather_37_validate_indices_0, x = var_423_shape_cast_fp16_to_uint16)[name = string("gather_37_cast_uint16")];
            string gather_37_cast_uint16_to_int32_dtype_0 = const()[name = string("gather_37_cast_uint16_to_int32_dtype_0"), val = string("int32")];
            int32 gather_38_axis_0 = const()[name = string("gather_38_axis_0"), val = int32(0)];
            int32 gather_38_batch_dims_0 = const()[name = string("gather_38_batch_dims_0"), val = int32(0)];
            bool gather_38_validate_indices_0 = const()[name = string("gather_38_validate_indices_0"), val = bool(false)];
            uint16 gather_38_indices_0_to_uint16 = const()[name = string("gather_38_indices_0_to_uint16"), val = uint16(1)];
            uint16 gather_38_cast_uint16 = gather(axis = gather_38_axis_0, batch_dims = gather_38_batch_dims_0, indices = gather_38_indices_0_to_uint16, validate_indices = gather_38_validate_indices_0, x = var_423_shape_cast_fp16_to_uint16)[name = string("gather_38_cast_uint16")];
            string gather_38_cast_uint16_to_int32_dtype_0 = const()[name = string("gather_38_cast_uint16_to_int32_dtype_0"), val = string("int32")];
            int32 concat_19_axis_0 = const()[name = string("concat_19_axis_0"), val = int32(0)];
            bool concat_19_interleave_0 = const()[name = string("concat_19_interleave_0"), val = bool(false)];
            int32 gather_38_cast_uint16_to_int32 = cast(dtype = gather_38_cast_uint16_to_int32_dtype_0, x = gather_38_cast_uint16)[name = string("cast_55")];
            int32 gather_37_cast_uint16_to_int32 = cast(dtype = gather_37_cast_uint16_to_int32_dtype_0, x = gather_37_cast_uint16)[name = string("cast_56")];
            tensor<int32, [4]> concat_19 = concat(axis = concat_19_axis_0, interleave = concat_19_interleave_0, values = (gather_37_cast_uint16_to_int32, gather_38_cast_uint16_to_int32, var_23, var_22))[name = string("concat_19")];
            tensor<fp16, [?, ?, 12, 32]> x_59_cast_fp16 = reshape(shape = concat_19, x = linear_24_cast_fp16)[name = string("x_59_cast_fp16")];
            bool attention_scores_17_transpose_x_0 = const()[name = string("attention_scores_17_transpose_x_0"), val = bool(false)];
            bool attention_scores_17_transpose_y_0 = const()[name = string("attention_scores_17_transpose_y_0"), val = bool(false)];
            tensor<int32, [4]> transpose_26_perm_0 = const()[name = string("transpose_26_perm_0"), val = tensor<int32, [4]>([0, 2, -3, -1])];
            tensor<int32, [4]> transpose_27_perm_0 = const()[name = string("transpose_27_perm_0"), val = tensor<int32, [4]>([0, 2, -1, -3])];
            tensor<fp16, [?, 12, 32, ?]> transpose_27 = transpose(perm = transpose_27_perm_0, x = x_51_cast_fp16)[name = string("transpose_35")];
            tensor<fp16, [?, 12, ?, 32]> transpose_26 = transpose(perm = transpose_26_perm_0, x = x_59_cast_fp16)[name = string("transpose_36")];
            tensor<fp16, [?, 12, ?, ?]> attention_scores_17_cast_fp16 = matmul(transpose_x = attention_scores_17_transpose_x_0, transpose_y = attention_scores_17_transpose_y_0, x = transpose_26, y = transpose_27)[name = string("attention_scores_17_cast_fp16")];
            fp16 _inversed_attention_scores_19_y_0_to_fp16 = const()[name = string("_inversed_attention_scores_19_y_0_to_fp16"), val = fp16(0x1.6ap-3)];
            tensor<fp16, [?, 12, ?, ?]> _inversed_attention_scores_19_cast_fp16 = mul(x = attention_scores_17_cast_fp16, y = _inversed_attention_scores_19_y_0_to_fp16)[name = string("_inversed_attention_scores_19_cast_fp16")];
            tensor<fp16, [?, 12, ?, ?]> input_99_cast_fp16 = add(x = _inversed_attention_scores_19_cast_fp16, y = attention_mask_cast_fp16)[name = string("input_99_cast_fp16")];
            tensor<fp16, [?, 12, ?, ?]> input_101_cast_fp16 = softmax(axis = var_24, x = input_99_cast_fp16)[name = string("input_101_cast_fp16")];
            bool context_layer_17_transpose_x_0 = const()[name = string("context_layer_17_transpose_x_0"), val = bool(false)];
            bool context_layer_17_transpose_y_0 = const()[name = string("context_layer_17_transpose_y_0"), val = bool(false)];
            tensor<fp16, [?, 12, ?, 32]> value_layer_9_cast_fp16 = transpose(perm = var_421, x = x_55_cast_fp16)[name = string("transpose_37")];
            tensor<fp16, [?, 12, ?, 32]> context_layer_17_cast_fp16 = matmul(transpose_x = context_layer_17_transpose_x_0, transpose_y = context_layer_17_transpose_y_0, x = input_101_cast_fp16, y = value_layer_9_cast_fp16)[name = string("context_layer_17_cast_fp16")];
            tensor<int32, [4]> var_437 = const()[name = string("op_437"), val = tensor<int32, [4]>([0, 2, 1, 3])];
            tensor<fp16, [?, ?, 12, 32]> var_438_cast_fp16 = transpose(perm = var_437, x = context_layer_17_cast_fp16)[name = string("transpose_34")];
            tensor<int32, [4]> var_440_shape_cast_fp16 = shape(x = var_438_cast_fp16)[name = string("op_440_shape_cast_fp16")];
            int32 gather_39_axis_0 = const()[name = string("gather_39_axis_0"), val = int32(0)];
            int32 gather_39_batch_dims_0 = const()[name = string("gather_39_batch_dims_0"), val = int32(0)];
            bool gather_39_validate_indices_0 = const()[name = string("gather_39_validate_indices_0"), val = bool(false)];
            string var_440_shape_cast_fp16_to_uint16_dtype_0 = const()[name = string("op_440_shape_cast_fp16_to_uint16_dtype_0"), val = string("uint16")];
            uint16 gather_39_indices_0_to_uint16 = const()[name = string("gather_39_indices_0_to_uint16"), val = uint16(0)];
            tensor<uint16, [4]> var_440_shape_cast_fp16_to_uint16 = cast(dtype = var_440_shape_cast_fp16_to_uint16_dtype_0, x = var_440_shape_cast_fp16)[name = string("cast_54")];
            uint16 gather_39_cast_uint16 = gather(axis = gather_39_axis_0, batch_dims = gather_39_batch_dims_0, indices = gather_39_indices_0_to_uint16, validate_indices = gather_39_validate_indices_0, x = var_440_shape_cast_fp16_to_uint16)[name = string("gather_39_cast_uint16")];
            string gather_39_cast_uint16_to_int32_dtype_0 = const()[name = string("gather_39_cast_uint16_to_int32_dtype_0"), val = string("int32")];
            int32 gather_40_axis_0 = const()[name = string("gather_40_axis_0"), val = int32(0)];
            int32 gather_40_batch_dims_0 = const()[name = string("gather_40_batch_dims_0"), val = int32(0)];
            bool gather_40_validate_indices_0 = const()[name = string("gather_40_validate_indices_0"), val = bool(false)];
            uint16 gather_40_indices_0_to_uint16 = const()[name = string("gather_40_indices_0_to_uint16"), val = uint16(1)];
            uint16 gather_40_cast_uint16 = gather(axis = gather_40_axis_0, batch_dims = gather_40_batch_dims_0, indices = gather_40_indices_0_to_uint16, validate_indices = gather_40_validate_indices_0, x = var_440_shape_cast_fp16_to_uint16)[name = string("gather_40_cast_uint16")];
            string gather_40_cast_uint16_to_int32_dtype_0 = const()[name = string("gather_40_cast_uint16_to_int32_dtype_0"), val = string("int32")];
            int32 concat_20_axis_0 = const()[name = string("concat_20_axis_0"), val = int32(0)];
            bool concat_20_interleave_0 = const()[name = string("concat_20_interleave_0"), val = bool(false)];
            int32 gather_40_cast_uint16_to_int32 = cast(dtype = gather_40_cast_uint16_to_int32_dtype_0, x = gather_40_cast_uint16)[name = string("cast_52")];
            int32 gather_39_cast_uint16_to_int32 = cast(dtype = gather_39_cast_uint16_to_int32_dtype_0, x = gather_39_cast_uint16)[name = string("cast_53")];
            tensor<int32, [3]> concat_20 = concat(axis = concat_20_axis_0, interleave = concat_20_interleave_0, values = (gather_39_cast_uint16_to_int32, gather_40_cast_uint16_to_int32, var_27))[name = string("concat_20")];
            tensor<fp16, [?, ?, 384]> input_103_cast_fp16 = reshape(shape = concat_20, x = var_438_cast_fp16)[name = string("input_103_cast_fp16")];
            tensor<fp16, [384, 384]> model_encoder_layer_4_attention_output_dense_weight_to_fp16 = const()[name = string("model_encoder_layer_4_attention_output_dense_weight_to_fp16"), val = tensor<fp16, [384, 384]>(BLOBFILE(path = string("@model_path/weights/weight.bin"), offset = uint64(38926912)))];
            tensor<fp16, [384]> model_encoder_layer_4_attention_output_dense_bias_to_fp16 = const()[name = string("model_encoder_layer_4_attention_output_dense_bias_to_fp16"), val = tensor<fp16, [384]>(BLOBFILE(path = string("@model_path/weights/weight.bin"), offset = uint64(39221888)))];
            tensor<fp16, [?, ?, 384]> linear_27_cast_fp16 = linear(bias = model_encoder_layer_4_attention_output_dense_bias_to_fp16, weight = model_encoder_layer_4_attention_output_dense_weight_to_fp16, x = input_103_cast_fp16)[name = string("linear_27_cast_fp16")];
            tensor<fp16, [?, ?, 384]> input_107_cast_fp16 = add(x = linear_27_cast_fp16, y = input_97_cast_fp16)[name = string("input_107_cast_fp16")];
            tensor<int32, [1]> input_109_axes_0 = const()[name = string("input_109_axes_0"), val = tensor<int32, [1]>([-1])];
            tensor<fp16, [384]> model_encoder_layer_4_attention_output_LayerNorm_weight_to_fp16 = const()[name = string("model_encoder_layer_4_attention_output_LayerNorm_weight_to_fp16"), val = tensor<fp16, [384]>(BLOBFILE(path = string("@model_path/weights/weight.bin"), offset = uint64(39222720)))];
            tensor<fp16, [384]> model_encoder_layer_4_attention_output_LayerNorm_bias_to_fp16 = const()[name = string("model_encoder_layer_4_attention_output_LayerNorm_bias_to_fp16"), val = tensor<fp16, [384]>(BLOBFILE(path = string("@model_path/weights/weight.bin"), offset = uint64(39223552)))];
            tensor<fp16, [?, ?, 384]> input_109_cast_fp16 = layer_norm(axes = input_109_axes_0, beta = model_encoder_layer_4_attention_output_LayerNorm_bias_to_fp16, epsilon = var_26_to_fp16, gamma = model_encoder_layer_4_attention_output_LayerNorm_weight_to_fp16, x = input_107_cast_fp16)[name = string("input_109_cast_fp16")];
            tensor<fp16, [1536, 384]> model_encoder_layer_4_intermediate_dense_weight_to_fp16 = const()[name = string("model_encoder_layer_4_intermediate_dense_weight_to_fp16"), val = tensor<fp16, [1536, 384]>(BLOBFILE(path = string("@model_path/weights/weight.bin"), offset = uint64(39224384)))];
            tensor<fp16, [1536]> model_encoder_layer_4_intermediate_dense_bias_to_fp16 = const()[name = string("model_encoder_layer_4_intermediate_dense_bias_to_fp16"), val = tensor<fp16, [1536]>(BLOBFILE(path = string("@model_path/weights/weight.bin"), offset = uint64(40404096)))];
            tensor<fp16, [?, ?, 1536]> linear_28_cast_fp16 = linear(bias = model_encoder_layer_4_intermediate_dense_bias_to_fp16, weight = model_encoder_layer_4_intermediate_dense_weight_to_fp16, x = input_109_cast_fp16)[name = string("linear_28_cast_fp16")];
            string input_113_mode_0 = const()[name = string("input_113_mode_0"), val = string("EXACT")];
            tensor<fp16, [?, ?, 1536]> input_113_cast_fp16 = gelu(mode = input_113_mode_0, x = linear_28_cast_fp16)[name = string("input_113_cast_fp16")];
            tensor<fp16, [384, 1536]> model_encoder_layer_4_output_dense_weight_to_fp16 = const()[name = string("model_encoder_layer_4_output_dense_weight_to_fp16"), val = tensor<fp16, [384, 1536]>(BLOBFILE(path = string("@model_path/weights/weight.bin"), offset = uint64(40407232)))];
            tensor<fp16, [384]> model_encoder_layer_4_output_dense_bias_to_fp16 = const()[name = string("model_encoder_layer_4_output_dense_bias_to_fp16"), val = tensor<fp16, [384]>(BLOBFILE(path = string("@model_path/weights/weight.bin"), offset = uint64(41586944)))];
            tensor<fp16, [?, ?, 384]> linear_29_cast_fp16 = linear(bias = model_encoder_layer_4_output_dense_bias_to_fp16, weight = model_encoder_layer_4_output_dense_weight_to_fp16, x = input_113_cast_fp16)[name = string("linear_29_cast_fp16")];
            tensor<fp16, [?, ?, 384]> input_117_cast_fp16 = add(x = linear_29_cast_fp16, y = input_109_cast_fp16)[name = string("input_117_cast_fp16")];
            tensor<int32, [1]> input_119_axes_0 = const()[name = string("input_119_axes_0"), val = tensor<int32, [1]>([-1])];
            tensor<fp16, [384]> model_encoder_layer_4_output_LayerNorm_weight_to_fp16 = const()[name = string("model_encoder_layer_4_output_LayerNorm_weight_to_fp16"), val = tensor<fp16, [384]>(BLOBFILE(path = string("@model_path/weights/weight.bin"), offset = uint64(41587776)))];
            tensor<fp16, [384]> model_encoder_layer_4_output_LayerNorm_bias_to_fp16 = const()[name = string("model_encoder_layer_4_output_LayerNorm_bias_to_fp16"), val = tensor<fp16, [384]>(BLOBFILE(path = string("@model_path/weights/weight.bin"), offset = uint64(41588608)))];
            tensor<fp16, [?, ?, 384]> input_119_cast_fp16 = layer_norm(axes = input_119_axes_0, beta = model_encoder_layer_4_output_LayerNorm_bias_to_fp16, epsilon = var_26_to_fp16, gamma = model_encoder_layer_4_output_LayerNorm_weight_to_fp16, x = input_117_cast_fp16)[name = string("input_119_cast_fp16")];
            tensor<fp16, [384, 384]> model_encoder_layer_5_attention_self_query_weight_to_fp16 = const()[name = string("model_encoder_layer_5_attention_self_query_weight_to_fp16"), val = tensor<fp16, [384, 384]>(BLOBFILE(path = string("@model_path/weights/weight.bin"), offset = uint64(41589440)))];
            tensor<fp16, [384]> model_encoder_layer_5_attention_self_query_bias_to_fp16 = const()[name = string("model_encoder_layer_5_attention_self_query_bias_to_fp16"), val = tensor<fp16, [384]>(BLOBFILE(path = string("@model_path/weights/weight.bin"), offset = uint64(41884416)))];
            tensor<fp16, [?, ?, 384]> linear_30_cast_fp16 = linear(bias = model_encoder_layer_5_attention_self_query_bias_to_fp16, weight = model_encoder_layer_5_attention_self_query_weight_to_fp16, x = input_119_cast_fp16)[name = string("linear_30_cast_fp16")];
            tensor<fp16, [384, 384]> model_encoder_layer_5_attention_self_key_weight_to_fp16 = const()[name = string("model_encoder_layer_5_attention_self_key_weight_to_fp16"), val = tensor<fp16, [384, 384]>(BLOBFILE(path = string("@model_path/weights/weight.bin"), offset = uint64(41885248)))];
            tensor<fp16, [384]> model_encoder_layer_5_attention_self_key_bias_to_fp16 = const()[name = string("model_encoder_layer_5_attention_self_key_bias_to_fp16"), val = tensor<fp16, [384]>(BLOBFILE(path = string("@model_path/weights/weight.bin"), offset = uint64(42180224)))];
            tensor<fp16, [?, ?, 384]> linear_31_cast_fp16 = linear(bias = model_encoder_layer_5_attention_self_key_bias_to_fp16, weight = model_encoder_layer_5_attention_self_key_weight_to_fp16, x = input_119_cast_fp16)[name = string("linear_31_cast_fp16")];
            tensor<int32, [3]> var_485_shape_cast_fp16 = shape(x = linear_31_cast_fp16)[name = string("op_485_shape_cast_fp16")];
            int32 gather_41_axis_0 = const()[name = string("gather_41_axis_0"), val = int32(0)];
            int32 gather_41_batch_dims_0 = const()[name = string("gather_41_batch_dims_0"), val = int32(0)];
            bool gather_41_validate_indices_0 = const()[name = string("gather_41_validate_indices_0"), val = bool(false)];
            string var_485_shape_cast_fp16_to_uint16_dtype_0 = const()[name = string("op_485_shape_cast_fp16_to_uint16_dtype_0"), val = string("uint16")];
            uint16 gather_41_indices_0_to_uint16 = const()[name = string("gather_41_indices_0_to_uint16"), val = uint16(0)];
            tensor<uint16, [3]> var_485_shape_cast_fp16_to_uint16 = cast(dtype = var_485_shape_cast_fp16_to_uint16_dtype_0, x = var_485_shape_cast_fp16)[name = string("cast_51")];
            uint16 gather_41_cast_uint16 = gather(axis = gather_41_axis_0, batch_dims = gather_41_batch_dims_0, indices = gather_41_indices_0_to_uint16, validate_indices = gather_41_validate_indices_0, x = var_485_shape_cast_fp16_to_uint16)[name = string("gather_41_cast_uint16")];
            string gather_41_cast_uint16_to_int32_dtype_0 = const()[name = string("gather_41_cast_uint16_to_int32_dtype_0"), val = string("int32")];
            int32 gather_42_axis_0 = const()[name = string("gather_42_axis_0"), val = int32(0)];
            int32 gather_42_batch_dims_0 = const()[name = string("gather_42_batch_dims_0"), val = int32(0)];
            bool gather_42_validate_indices_0 = const()[name = string("gather_42_validate_indices_0"), val = bool(false)];
            uint16 gather_42_indices_0_to_uint16 = const()[name = string("gather_42_indices_0_to_uint16"), val = uint16(1)];
            uint16 gather_42_cast_uint16 = gather(axis = gather_42_axis_0, batch_dims = gather_42_batch_dims_0, indices = gather_42_indices_0_to_uint16, validate_indices = gather_42_validate_indices_0, x = var_485_shape_cast_fp16_to_uint16)[name = string("gather_42_cast_uint16")];
            string gather_42_cast_uint16_to_int32_dtype_0 = const()[name = string("gather_42_cast_uint16_to_int32_dtype_0"), val = string("int32")];
            int32 concat_21_axis_0 = const()[name = string("concat_21_axis_0"), val = int32(0)];
            bool concat_21_interleave_0 = const()[name = string("concat_21_interleave_0"), val = bool(false)];
            int32 gather_42_cast_uint16_to_int32 = cast(dtype = gather_42_cast_uint16_to_int32_dtype_0, x = gather_42_cast_uint16)[name = string("cast_49")];
            int32 gather_41_cast_uint16_to_int32 = cast(dtype = gather_41_cast_uint16_to_int32_dtype_0, x = gather_41_cast_uint16)[name = string("cast_50")];
            tensor<int32, [4]> concat_21 = concat(axis = concat_21_axis_0, interleave = concat_21_interleave_0, values = (gather_41_cast_uint16_to_int32, gather_42_cast_uint16_to_int32, var_23, var_22))[name = string("concat_21")];
            tensor<fp16, [?, ?, 12, 32]> x_63_cast_fp16 = reshape(shape = concat_21, x = linear_31_cast_fp16)[name = string("x_63_cast_fp16")];
            tensor<fp16, [384, 384]> model_encoder_layer_5_attention_self_value_weight_to_fp16 = const()[name = string("model_encoder_layer_5_attention_self_value_weight_to_fp16"), val = tensor<fp16, [384, 384]>(BLOBFILE(path = string("@model_path/weights/weight.bin"), offset = uint64(42181056)))];
            tensor<fp16, [384]> model_encoder_layer_5_attention_self_value_bias_to_fp16 = const()[name = string("model_encoder_layer_5_attention_self_value_bias_to_fp16"), val = tensor<fp16, [384]>(BLOBFILE(path = string("@model_path/weights/weight.bin"), offset = uint64(42476032)))];
            tensor<fp16, [?, ?, 384]> linear_32_cast_fp16 = linear(bias = model_encoder_layer_5_attention_self_value_bias_to_fp16, weight = model_encoder_layer_5_attention_self_value_weight_to_fp16, x = input_119_cast_fp16)[name = string("linear_32_cast_fp16")];
            tensor<int32, [3]> var_494_shape_cast_fp16 = shape(x = linear_32_cast_fp16)[name = string("op_494_shape_cast_fp16")];
            int32 gather_43_axis_0 = const()[name = string("gather_43_axis_0"), val = int32(0)];
            int32 gather_43_batch_dims_0 = const()[name = string("gather_43_batch_dims_0"), val = int32(0)];
            bool gather_43_validate_indices_0 = const()[name = string("gather_43_validate_indices_0"), val = bool(false)];
            string var_494_shape_cast_fp16_to_uint16_dtype_0 = const()[name = string("op_494_shape_cast_fp16_to_uint16_dtype_0"), val = string("uint16")];
            uint16 gather_43_indices_0_to_uint16 = const()[name = string("gather_43_indices_0_to_uint16"), val = uint16(0)];
            tensor<uint16, [3]> var_494_shape_cast_fp16_to_uint16 = cast(dtype = var_494_shape_cast_fp16_to_uint16_dtype_0, x = var_494_shape_cast_fp16)[name = string("cast_48")];
            uint16 gather_43_cast_uint16 = gather(axis = gather_43_axis_0, batch_dims = gather_43_batch_dims_0, indices = gather_43_indices_0_to_uint16, validate_indices = gather_43_validate_indices_0, x = var_494_shape_cast_fp16_to_uint16)[name = string("gather_43_cast_uint16")];
            string gather_43_cast_uint16_to_int32_dtype_0 = const()[name = string("gather_43_cast_uint16_to_int32_dtype_0"), val = string("int32")];
            int32 gather_44_axis_0 = const()[name = string("gather_44_axis_0"), val = int32(0)];
            int32 gather_44_batch_dims_0 = const()[name = string("gather_44_batch_dims_0"), val = int32(0)];
            bool gather_44_validate_indices_0 = const()[name = string("gather_44_validate_indices_0"), val = bool(false)];
            uint16 gather_44_indices_0_to_uint16 = const()[name = string("gather_44_indices_0_to_uint16"), val = uint16(1)];
            uint16 gather_44_cast_uint16 = gather(axis = gather_44_axis_0, batch_dims = gather_44_batch_dims_0, indices = gather_44_indices_0_to_uint16, validate_indices = gather_44_validate_indices_0, x = var_494_shape_cast_fp16_to_uint16)[name = string("gather_44_cast_uint16")];
            string gather_44_cast_uint16_to_int32_dtype_0 = const()[name = string("gather_44_cast_uint16_to_int32_dtype_0"), val = string("int32")];
            int32 concat_22_axis_0 = const()[name = string("concat_22_axis_0"), val = int32(0)];
            bool concat_22_interleave_0 = const()[name = string("concat_22_interleave_0"), val = bool(false)];
            int32 gather_44_cast_uint16_to_int32 = cast(dtype = gather_44_cast_uint16_to_int32_dtype_0, x = gather_44_cast_uint16)[name = string("cast_46")];
            int32 gather_43_cast_uint16_to_int32 = cast(dtype = gather_43_cast_uint16_to_int32_dtype_0, x = gather_43_cast_uint16)[name = string("cast_47")];
            tensor<int32, [4]> concat_22 = concat(axis = concat_22_axis_0, interleave = concat_22_interleave_0, values = (gather_43_cast_uint16_to_int32, gather_44_cast_uint16_to_int32, var_23, var_22))[name = string("concat_22")];
            tensor<fp16, [?, ?, 12, 32]> x_67_cast_fp16 = reshape(shape = concat_22, x = linear_32_cast_fp16)[name = string("x_67_cast_fp16")];
            tensor<int32, [4]> var_498 = const()[name = string("op_498"), val = tensor<int32, [4]>([0, 2, 1, 3])];
            tensor<int32, [3]> var_500_shape_cast_fp16 = shape(x = linear_30_cast_fp16)[name = string("op_500_shape_cast_fp16")];
            int32 gather_45_axis_0 = const()[name = string("gather_45_axis_0"), val = int32(0)];
            int32 gather_45_batch_dims_0 = const()[name = string("gather_45_batch_dims_0"), val = int32(0)];
            bool gather_45_validate_indices_0 = const()[name = string("gather_45_validate_indices_0"), val = bool(false)];
            string var_500_shape_cast_fp16_to_uint16_dtype_0 = const()[name = string("op_500_shape_cast_fp16_to_uint16_dtype_0"), val = string("uint16")];
            uint16 gather_45_indices_0_to_uint16 = const()[name = string("gather_45_indices_0_to_uint16"), val = uint16(0)];
            tensor<uint16, [3]> var_500_shape_cast_fp16_to_uint16 = cast(dtype = var_500_shape_cast_fp16_to_uint16_dtype_0, x = var_500_shape_cast_fp16)[name = string("cast_45")];
            uint16 gather_45_cast_uint16 = gather(axis = gather_45_axis_0, batch_dims = gather_45_batch_dims_0, indices = gather_45_indices_0_to_uint16, validate_indices = gather_45_validate_indices_0, x = var_500_shape_cast_fp16_to_uint16)[name = string("gather_45_cast_uint16")];
            string gather_45_cast_uint16_to_int32_dtype_0 = const()[name = string("gather_45_cast_uint16_to_int32_dtype_0"), val = string("int32")];
            int32 gather_46_axis_0 = const()[name = string("gather_46_axis_0"), val = int32(0)];
            int32 gather_46_batch_dims_0 = const()[name = string("gather_46_batch_dims_0"), val = int32(0)];
            bool gather_46_validate_indices_0 = const()[name = string("gather_46_validate_indices_0"), val = bool(false)];
            uint16 gather_46_indices_0_to_uint16 = const()[name = string("gather_46_indices_0_to_uint16"), val = uint16(1)];
            uint16 gather_46_cast_uint16 = gather(axis = gather_46_axis_0, batch_dims = gather_46_batch_dims_0, indices = gather_46_indices_0_to_uint16, validate_indices = gather_46_validate_indices_0, x = var_500_shape_cast_fp16_to_uint16)[name = string("gather_46_cast_uint16")];
            string gather_46_cast_uint16_to_int32_dtype_0 = const()[name = string("gather_46_cast_uint16_to_int32_dtype_0"), val = string("int32")];
            int32 concat_23_axis_0 = const()[name = string("concat_23_axis_0"), val = int32(0)];
            bool concat_23_interleave_0 = const()[name = string("concat_23_interleave_0"), val = bool(false)];
            int32 gather_46_cast_uint16_to_int32 = cast(dtype = gather_46_cast_uint16_to_int32_dtype_0, x = gather_46_cast_uint16)[name = string("cast_43")];
            int32 gather_45_cast_uint16_to_int32 = cast(dtype = gather_45_cast_uint16_to_int32_dtype_0, x = gather_45_cast_uint16)[name = string("cast_44")];
            tensor<int32, [4]> concat_23 = concat(axis = concat_23_axis_0, interleave = concat_23_interleave_0, values = (gather_45_cast_uint16_to_int32, gather_46_cast_uint16_to_int32, var_23, var_22))[name = string("concat_23")];
            tensor<fp16, [?, ?, 12, 32]> x_cast_fp16 = reshape(shape = concat_23, x = linear_30_cast_fp16)[name = string("x_cast_fp16")];
            bool attention_scores_21_transpose_x_0 = const()[name = string("attention_scores_21_transpose_x_0"), val = bool(false)];
            bool attention_scores_21_transpose_y_0 = const()[name = string("attention_scores_21_transpose_y_0"), val = bool(false)];
            tensor<int32, [4]> transpose_28_perm_0 = const()[name = string("transpose_28_perm_0"), val = tensor<int32, [4]>([0, 2, -3, -1])];
            tensor<int32, [4]> transpose_29_perm_0 = const()[name = string("transpose_29_perm_0"), val = tensor<int32, [4]>([0, 2, -1, -3])];
            tensor<fp16, [?, 12, 32, ?]> transpose_29 = transpose(perm = transpose_29_perm_0, x = x_63_cast_fp16)[name = string("transpose_31")];
            tensor<fp16, [?, 12, ?, 32]> transpose_28 = transpose(perm = transpose_28_perm_0, x = x_cast_fp16)[name = string("transpose_32")];
            tensor<fp16, [?, 12, ?, ?]> attention_scores_21_cast_fp16 = matmul(transpose_x = attention_scores_21_transpose_x_0, transpose_y = attention_scores_21_transpose_y_0, x = transpose_28, y = transpose_29)[name = string("attention_scores_21_cast_fp16")];
            fp16 _inversed_attention_scores_y_0_to_fp16 = const()[name = string("_inversed_attention_scores_y_0_to_fp16"), val = fp16(0x1.6ap-3)];
            tensor<fp16, [?, 12, ?, ?]> _inversed_attention_scores_cast_fp16 = mul(x = attention_scores_21_cast_fp16, y = _inversed_attention_scores_y_0_to_fp16)[name = string("_inversed_attention_scores_cast_fp16")];
            tensor<fp16, [?, 12, ?, ?]> input_121_cast_fp16 = add(x = _inversed_attention_scores_cast_fp16, y = attention_mask_cast_fp16)[name = string("input_121_cast_fp16")];
            tensor<fp16, [?, 12, ?, ?]> input_123_cast_fp16 = softmax(axis = var_24, x = input_121_cast_fp16)[name = string("input_123_cast_fp16")];
            bool context_layer_21_transpose_x_0 = const()[name = string("context_layer_21_transpose_x_0"), val = bool(false)];
            bool context_layer_21_transpose_y_0 = const()[name = string("context_layer_21_transpose_y_0"), val = bool(false)];
            tensor<fp16, [?, 12, ?, 32]> value_layer_cast_fp16 = transpose(perm = var_498, x = x_67_cast_fp16)[name = string("transpose_33")];
            tensor<fp16, [?, 12, ?, 32]> context_layer_21_cast_fp16 = matmul(transpose_x = context_layer_21_transpose_x_0, transpose_y = context_layer_21_transpose_y_0, x = input_123_cast_fp16, y = value_layer_cast_fp16)[name = string("context_layer_21_cast_fp16")];
            tensor<int32, [4]> var_514 = const()[name = string("op_514"), val = tensor<int32, [4]>([0, 2, 1, 3])];
            tensor<fp16, [?, ?, 12, 32]> var_515_cast_fp16 = transpose(perm = var_514, x = context_layer_21_cast_fp16)[name = string("transpose_30")];
            tensor<int32, [4]> var_517_shape_cast_fp16 = shape(x = var_515_cast_fp16)[name = string("op_517_shape_cast_fp16")];
            int32 gather_47_axis_0 = const()[name = string("gather_47_axis_0"), val = int32(0)];
            int32 gather_47_batch_dims_0 = const()[name = string("gather_47_batch_dims_0"), val = int32(0)];
            bool gather_47_validate_indices_0 = const()[name = string("gather_47_validate_indices_0"), val = bool(false)];
            string var_517_shape_cast_fp16_to_uint16_dtype_0 = const()[name = string("op_517_shape_cast_fp16_to_uint16_dtype_0"), val = string("uint16")];
            uint16 gather_47_indices_0_to_uint16 = const()[name = string("gather_47_indices_0_to_uint16"), val = uint16(0)];
            tensor<uint16, [4]> var_517_shape_cast_fp16_to_uint16 = cast(dtype = var_517_shape_cast_fp16_to_uint16_dtype_0, x = var_517_shape_cast_fp16)[name = string("cast_42")];
            uint16 gather_47_cast_uint16 = gather(axis = gather_47_axis_0, batch_dims = gather_47_batch_dims_0, indices = gather_47_indices_0_to_uint16, validate_indices = gather_47_validate_indices_0, x = var_517_shape_cast_fp16_to_uint16)[name = string("gather_47_cast_uint16")];
            string gather_47_cast_uint16_to_int32_dtype_0 = const()[name = string("gather_47_cast_uint16_to_int32_dtype_0"), val = string("int32")];
            int32 gather_48_axis_0 = const()[name = string("gather_48_axis_0"), val = int32(0)];
            int32 gather_48_batch_dims_0 = const()[name = string("gather_48_batch_dims_0"), val = int32(0)];
            bool gather_48_validate_indices_0 = const()[name = string("gather_48_validate_indices_0"), val = bool(false)];
            uint16 gather_48_indices_0_to_uint16 = const()[name = string("gather_48_indices_0_to_uint16"), val = uint16(1)];
            uint16 gather_48_cast_uint16 = gather(axis = gather_48_axis_0, batch_dims = gather_48_batch_dims_0, indices = gather_48_indices_0_to_uint16, validate_indices = gather_48_validate_indices_0, x = var_517_shape_cast_fp16_to_uint16)[name = string("gather_48_cast_uint16")];
            string gather_48_cast_uint16_to_int32_dtype_0 = const()[name = string("gather_48_cast_uint16_to_int32_dtype_0"), val = string("int32")];
            int32 concat_24_axis_0 = const()[name = string("concat_24_axis_0"), val = int32(0)];
            bool concat_24_interleave_0 = const()[name = string("concat_24_interleave_0"), val = bool(false)];
            int32 gather_48_cast_uint16_to_int32 = cast(dtype = gather_48_cast_uint16_to_int32_dtype_0, x = gather_48_cast_uint16)[name = string("cast_40")];
            int32 gather_47_cast_uint16_to_int32 = cast(dtype = gather_47_cast_uint16_to_int32_dtype_0, x = gather_47_cast_uint16)[name = string("cast_41")];
            tensor<int32, [3]> concat_24 = concat(axis = concat_24_axis_0, interleave = concat_24_interleave_0, values = (gather_47_cast_uint16_to_int32, gather_48_cast_uint16_to_int32, var_27))[name = string("concat_24")];
            tensor<fp16, [?, ?, 384]> input_125_cast_fp16 = reshape(shape = concat_24, x = var_515_cast_fp16)[name = string("input_125_cast_fp16")];
            tensor<fp16, [384, 384]> model_encoder_layer_5_attention_output_dense_weight_to_fp16 = const()[name = string("model_encoder_layer_5_attention_output_dense_weight_to_fp16"), val = tensor<fp16, [384, 384]>(BLOBFILE(path = string("@model_path/weights/weight.bin"), offset = uint64(42476864)))];
            tensor<fp16, [384]> model_encoder_layer_5_attention_output_dense_bias_to_fp16 = const()[name = string("model_encoder_layer_5_attention_output_dense_bias_to_fp16"), val = tensor<fp16, [384]>(BLOBFILE(path = string("@model_path/weights/weight.bin"), offset = uint64(42771840)))];
            tensor<fp16, [?, ?, 384]> linear_33_cast_fp16 = linear(bias = model_encoder_layer_5_attention_output_dense_bias_to_fp16, weight = model_encoder_layer_5_attention_output_dense_weight_to_fp16, x = input_125_cast_fp16)[name = string("linear_33_cast_fp16")];
            tensor<fp16, [?, ?, 384]> input_129_cast_fp16 = add(x = linear_33_cast_fp16, y = input_119_cast_fp16)[name = string("input_129_cast_fp16")];
            tensor<int32, [1]> input_131_axes_0 = const()[name = string("input_131_axes_0"), val = tensor<int32, [1]>([-1])];
            tensor<fp16, [384]> model_encoder_layer_5_attention_output_LayerNorm_weight_to_fp16 = const()[name = string("model_encoder_layer_5_attention_output_LayerNorm_weight_to_fp16"), val = tensor<fp16, [384]>(BLOBFILE(path = string("@model_path/weights/weight.bin"), offset = uint64(42772672)))];
            tensor<fp16, [384]> model_encoder_layer_5_attention_output_LayerNorm_bias_to_fp16 = const()[name = string("model_encoder_layer_5_attention_output_LayerNorm_bias_to_fp16"), val = tensor<fp16, [384]>(BLOBFILE(path = string("@model_path/weights/weight.bin"), offset = uint64(42773504)))];
            tensor<fp16, [?, ?, 384]> input_131_cast_fp16 = layer_norm(axes = input_131_axes_0, beta = model_encoder_layer_5_attention_output_LayerNorm_bias_to_fp16, epsilon = var_26_to_fp16, gamma = model_encoder_layer_5_attention_output_LayerNorm_weight_to_fp16, x = input_129_cast_fp16)[name = string("input_131_cast_fp16")];
            tensor<fp16, [1536, 384]> model_encoder_layer_5_intermediate_dense_weight_to_fp16 = const()[name = string("model_encoder_layer_5_intermediate_dense_weight_to_fp16"), val = tensor<fp16, [1536, 384]>(BLOBFILE(path = string("@model_path/weights/weight.bin"), offset = uint64(42774336)))];
            tensor<fp16, [1536]> model_encoder_layer_5_intermediate_dense_bias_to_fp16 = const()[name = string("model_encoder_layer_5_intermediate_dense_bias_to_fp16"), val = tensor<fp16, [1536]>(BLOBFILE(path = string("@model_path/weights/weight.bin"), offset = uint64(43954048)))];
            tensor<fp16, [?, ?, 1536]> linear_34_cast_fp16 = linear(bias = model_encoder_layer_5_intermediate_dense_bias_to_fp16, weight = model_encoder_layer_5_intermediate_dense_weight_to_fp16, x = input_131_cast_fp16)[name = string("linear_34_cast_fp16")];
            string input_135_mode_0 = const()[name = string("input_135_mode_0"), val = string("EXACT")];
            tensor<fp16, [?, ?, 1536]> input_135_cast_fp16 = gelu(mode = input_135_mode_0, x = linear_34_cast_fp16)[name = string("input_135_cast_fp16")];
            tensor<fp16, [384, 1536]> model_encoder_layer_5_output_dense_weight_to_fp16 = const()[name = string("model_encoder_layer_5_output_dense_weight_to_fp16"), val = tensor<fp16, [384, 1536]>(BLOBFILE(path = string("@model_path/weights/weight.bin"), offset = uint64(43957184)))];
            tensor<fp16, [384]> model_encoder_layer_5_output_dense_bias_to_fp16 = const()[name = string("model_encoder_layer_5_output_dense_bias_to_fp16"), val = tensor<fp16, [384]>(BLOBFILE(path = string("@model_path/weights/weight.bin"), offset = uint64(45136896)))];
            tensor<fp16, [?, ?, 384]> linear_35_cast_fp16 = linear(bias = model_encoder_layer_5_output_dense_bias_to_fp16, weight = model_encoder_layer_5_output_dense_weight_to_fp16, x = input_135_cast_fp16)[name = string("linear_35_cast_fp16")];
            tensor<fp16, [?, ?, 384]> input_139_cast_fp16 = add(x = linear_35_cast_fp16, y = input_131_cast_fp16)[name = string("input_139_cast_fp16")];
            tensor<int32, [1]> hidden_states_axes_0 = const()[name = string("hidden_states_axes_0"), val = tensor<int32, [1]>([-1])];
            tensor<fp16, [384]> model_encoder_layer_5_output_LayerNorm_weight_to_fp16 = const()[name = string("model_encoder_layer_5_output_LayerNorm_weight_to_fp16"), val = tensor<fp16, [384]>(BLOBFILE(path = string("@model_path/weights/weight.bin"), offset = uint64(45137728)))];
            tensor<fp16, [384]> model_encoder_layer_5_output_LayerNorm_bias_to_fp16 = const()[name = string("model_encoder_layer_5_output_LayerNorm_bias_to_fp16"), val = tensor<fp16, [384]>(BLOBFILE(path = string("@model_path/weights/weight.bin"), offset = uint64(45138560)))];
            tensor<fp16, [?, ?, 384]> hidden_states_cast_fp16 = layer_norm(axes = hidden_states_axes_0, beta = model_encoder_layer_5_output_LayerNorm_bias_to_fp16, epsilon = var_26_to_fp16, gamma = model_encoder_layer_5_output_LayerNorm_weight_to_fp16, x = input_139_cast_fp16)[name = string("hidden_states_cast_fp16")];
            tensor<int32, [3]> input_141_begin_0 = const()[name = string("input_141_begin_0"), val = tensor<int32, [3]>([0, 0, 0])];
            tensor<int32, [3]> input_141_end_0 = const()[name = string("input_141_end_0"), val = tensor<int32, [3]>([0, 1, 384])];
            tensor<bool, [3]> input_141_end_mask_0 = const()[name = string("input_141_end_mask_0"), val = tensor<bool, [3]>([true, false, true])];
            tensor<bool, [3]> input_141_squeeze_mask_0 = const()[name = string("input_141_squeeze_mask_0"), val = tensor<bool, [3]>([false, true, false])];
            tensor<fp16, [?, 384]> input_141_cast_fp16 = slice_by_index(begin = input_141_begin_0, end = input_141_end_0, end_mask = input_141_end_mask_0, squeeze_mask = input_141_squeeze_mask_0, x = hidden_states_cast_fp16)[name = string("input_141_cast_fp16")];
            tensor<fp16, [384, 384]> model_pooler_dense_weight_to_fp16 = const()[name = string("model_pooler_dense_weight_to_fp16"), val = tensor<fp16, [384, 384]>(BLOBFILE(path = string("@model_path/weights/weight.bin"), offset = uint64(45139392)))];
            tensor<fp16, [384]> model_pooler_dense_bias_to_fp16 = const()[name = string("model_pooler_dense_bias_to_fp16"), val = tensor<fp16, [384]>(BLOBFILE(path = string("@model_path/weights/weight.bin"), offset = uint64(45434368)))];
            tensor<fp16, [?, 384]> linear_36_cast_fp16 = linear(bias = model_pooler_dense_bias_to_fp16, weight = model_pooler_dense_weight_to_fp16, x = input_141_cast_fp16)[name = string("linear_36_cast_fp16")];
            tensor<fp16, [?, 384]> var_554 = tanh(x = linear_36_cast_fp16)[name = string("op_554_cast_fp16")];
        } -> (var_554);
}