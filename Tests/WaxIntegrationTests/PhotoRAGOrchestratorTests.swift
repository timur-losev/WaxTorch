import Foundation
import CoreGraphics
import Testing
import Wax

private struct StubMultimodalEmbedder: MultimodalEmbeddingProvider {
    let dimensions: Int = 4
    let normalize: Bool = true
    let identity: EmbeddingIdentity? = EmbeddingIdentity(provider: "stub", model: "stub", dimensions: 4, normalized: true)

    func embed(text: String) async throws -> [Float] { [1, 0, 0, 0] }
    func embed(image: CGImage) async throws -> [Float] { [0, 1, 0, 0] }
}

@Test
func photoRAGRecallReturnsAssetIDsFromOCR() async throws {
    try await TempFiles.withTempFile { url in
        let wax = try await Wax.create(at: url)
        let sessionConfig = WaxSession.Config(
            enableTextSearch: true,
            enableVectorSearch: true,
            enableStructuredMemory: false,
            vectorEnginePreference: .cpuOnly,
            vectorMetric: .cosine,
            vectorDimensions: 4
        )
        let session = try await wax.openSession(.readWrite(.wait), config: sessionConfig)

        let captureMs: Int64 = 1_700_000_000_000
        var metaA = Metadata()
        metaA.entries["photos.asset_id"] = "A"
        metaA.entries["photo.capture_ms"] = String(captureMs)

        let rootA = try await session.put(
            Data(),
            embedding: [1, 0, 0, 0],
            identity: nil,
            options: FrameMetaSubset(kind: "photo.root", metadata: metaA),
            compression: .plain,
            timestampMs: captureMs
        )

        let ocrTextA = "COSTCO WHOLESALE\nTOTAL 42.00"
        let ocrA = try await session.put(
            Data(ocrTextA.utf8),
            options: FrameMetaSubset(kind: "photo.ocr.summary", role: .blob, parentId: rootA, metadata: metaA),
            compression: .plain,
            timestampMs: captureMs
        )
        try await session.indexText(frameId: ocrA, text: ocrTextA)

        var metaB = Metadata()
        metaB.entries["photos.asset_id"] = "B"
        metaB.entries["photo.capture_ms"] = String(captureMs)

        let rootB = try await session.put(
            Data(),
            embedding: [0, 1, 0, 0],
            identity: nil,
            options: FrameMetaSubset(kind: "photo.root", metadata: metaB),
            compression: .plain,
            timestampMs: captureMs
        )

        let ocrTextB = "Hello World"
        let ocrB = try await session.put(
            Data(ocrTextB.utf8),
            options: FrameMetaSubset(kind: "photo.ocr.summary", role: .blob, parentId: rootB, metadata: metaB),
            compression: .plain,
            timestampMs: captureMs
        )
        try await session.indexText(frameId: ocrB, text: ocrTextB)

        try await session.commit()
        await session.close()
        try await wax.close()

        var config = PhotoRAGConfig.default
        config.includeThumbnailsInContext = false
        config.includeRegionCropsInContext = false
        config.enableOCR = false
        config.enableRegionEmbeddings = false
        config.vectorEnginePreference = .cpuOnly

        let orchestrator = try await PhotoRAGOrchestrator(
            storeURL: url,
            config: config,
            embedder: StubMultimodalEmbedder()
        )

        let query = PhotoQuery(
            text: "Costco",
            image: nil,
            timeRange: nil,
            location: nil,
            filters: .none,
            resultLimit: 5,
            contextBudget: ContextBudget(maxTextTokens: 400, maxImages: 0, maxRegions: 0, maxOCRLinesPerItem: 4)
        )

        let ctx = try await orchestrator.recall(query)
        #expect(!ctx.items.isEmpty)
        #expect(ctx.items.first?.assetID == "A")
        #expect(ctx.items.first?.summaryText.contains("COSTCO") == true)
        try await orchestrator.flush()
    }
}
