

![unnamed-11](https://github.com/user-attachments/assets/5740a66d-21c2-4980-b6be-06ab1ff1bc68)

# ğŸ¯ Wax  
### The Swift-native, single-file memory engine for AI

**Persistent, on-device RAG â€” without servers, databases, or pipelines.**

| ğŸ§  On-device memory | ğŸ” Hybrid search | ğŸ’¾ Single-file persistence |
|---|---|---|

Wax is a **portable AI memory system** that packages:
- your data
- embeddings
- search indexes
- metadata
- and recovery logs  

into **one deterministic file**.

Instead of shipping fragile RAG stacks or depending on server-side vector databases,  
**Wax lets AI retrieve knowledge directly from disk â€” fast, offline, and reproducibly.**

Your agent doesnâ€™t *query infrastructure*.  
It **carries its memory with it.**

â­ If this repo is useful, please consider starring it â€” it genuinely helps.

---

## Why Wax exists

Most RAG systems assume:
- ğŸŒ cloud inference
- ğŸ§± external vector databases
- ğŸ•¸ network latency
- ğŸ”“ data leaving the device
- ğŸ§® non-deterministic context assembly

Wax flips that model:

- **100% on-device**
- **single-file state**
- **crash-safe by default**
- **deterministic retrieval**
- **Swift-native concurrency**

This makes Wax ideal for **agents, assistants, research tools, and privacy-first apps** that need *real memory*, not prompt hacks.

---

## ğŸ“Š Performance (Apple Silicon)

Wax is designed for **interactive latency**, not server throughput.

| Benchmark | Result | Notes |
|---------|--------|-------|
| **Hybrid search @ 10K docs** | 105ms | Near-constant scaling |
| **Metal GPU vector search (warm)** | 0.84ms | 10K Ã— 384-dim |
| **Cold open â†’ first query** | 17ms p50 | Ready for interactive use |
| **GPU warm vs cold** | 10.9Ã— faster | Lazy sync |
| **Buffer serialization** | 16.5Ã— faster | vs file I/O |

<details>
<summary><b>Full benchmark breakdown</b></summary>

### Core RAG Pipeline

| Test | Avg Latency | RSD |
|------|-------------|-----|
| Hybrid Search @ 1K docs | 105ms | 3.4% |
| FastRAG DenseCached | 105ms | 3.4% |
| FastRAG Fast Mode | 106ms | 3.1% |
| Orchestrator Ingest (batched) | 309ms | 1.7% |
| Cold Open + First Search | 599ms | â€” |

### Metal GPU Performance

| Metric | Value |
|--------|-------|
| Search latency (1K Ã— 128d) | 1.86ms avg |
| Latency per vector | 0.0019ms |
| Cold sync (10K Ã— 384d) | 9.19ms |
| Warm search (10K Ã— 384d) | 0.84ms |
| Memory saved per warm query | 14.6 MB |

*Benchmarks run on Apple Silicon. Run `swift test --filter RAGPerformanceBenchmarks` to reproduce.*  
*Optional benchmark suites are opt-in via env flags: `WAX_BENCHMARK_MINILM=1`, `WAX_BENCHMARK_METAL=1`, `WAX_BENCHMARK_10K=1`, `WAX_BENCHMARK_METRICS=1`, `WAX_BENCHMARK_SAMPLES=1`, `WAX_BENCHMARK_OPTIMIZATION=1`.*

</details>

---

## âœ¨ What makes Wax different

**Stop shipping AI that forgets.**

Wax gives your users AI that:
- remembers across launches
- survives crashes
- behaves deterministically
- works offline
- scales without infra

**The core advantages:**

- ğŸ§  **One file, complete memory**  
  A single `.mv2s` file contains data, indexes, and WAL â€” nothing else required.

- ğŸ”’ **Crash-safe persistence**  
  Power loss, app kills, and upgrades are first-class concerns, not edge cases.

- âš¡ **Hybrid retrieval engine**  
  Lexical + vector + temporal fusion, tuned for on-device latency.

- ğŸ§® **Deterministic RAG**  
  Stable token counts and reproducible contexts â€” ideal for research and testing.

- ğŸ­ **Swift-native design**  
  Actor-isolated, async-first, written for Swift 6.2 concurrency.

- ğŸ§© **Composable by design**  
  Use Wax as a store, a search engine, or a full RAG pipeline.

---

## ğŸš€ Perfect for

- **AI assistants** that remember users over time  
- **Offline-first apps** with serious search requirements  
- **Privacy-critical products** where data never leaves the device  
- **Research tooling** that needs reproducible retrieval  
- **Agent workflows** that require durable state

---

If Wax saved you time, removed infrastructure, or made on-device AI simpler,  
**consider starring the repo** â­ â€” it helps guide the projectâ€™s direction.

## Architectural Choices

- **Actor-owned core (`Wax`)**: isolates mutable state and I/O, making correctness the default on mobile.
- **Append-only frames + WAL**: fast writes, safe recovery, and predictable performance under load.
- **Two-phase indexing**: stage, then commit; keeps ingestion fast while guaranteeing atomic index updates.
- **Adaptive hybrid fusion**: query-typeâ€“aware weighting (text/vector/temporal) improves relevance without user tuning.
- **Deterministic RAG builder**: single expansion + ranked snippets + surrogate support gives stable, testable contexts.
- **Protocol-driven embeddings**: swap local models without touching the core store or search paths.

## Researcher Notes

- Deterministic token counting and truncation (cl100k_base).
- Unified retrieval with query-type adaptive fusion.
- Reproducible RAG contexts (single expansion, ranked snippets, surrogate support).

## Requirements

- Swift 6.2
- iOS 26 / macOS 26

## Installation

Add Wax as a Swift Package dependency.

```swift
.package(url: ["<REPO_URL>"](https://github.com/christopherkarani/Wax), from: "0.1.1")
```

Then add targets as needed:

```swift
.product(name: "Wax", package: "Wax")
```

## Contributing

We welcome issues and PRs. For local validation:

```bash
cd Wax
swift test
```

If you're exploring the MV2S format or retrieval research, start with `MV2S_SPEC.md` and the phase docs. We are especially interested in:
- Retrieval quality evaluations and reproducibility studies
- On-device memory benchmarks
- New embedding adapters and pruning/compaction strategies
